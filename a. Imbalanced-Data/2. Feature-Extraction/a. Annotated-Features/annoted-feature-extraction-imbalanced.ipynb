{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Extraction Methods: Imbalanced Data With Annotations**\n",
    "\n",
    "- *Key Features*: [MFCCs, Mel-Spectrograms, Chroma Frequencies, RMS Power]\n",
    "- *Key Manipulations*: [Varying Window Sizes, Normalization, Average Pooling (Compression), Filtering]\n",
    "- *Process Assistence*: [Converting them to numpy arrays now, easy label access across features]\n",
    "- *Conversion*: [To numpy arrays and pkl files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Libraries for audio\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Training and Testing Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for normalization & avgpooling features\n",
    "import tensorflow as tf\n",
    "# for preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Operational\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabels to be reused\n",
    "path = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/audio_files' \n",
    "npy_path = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/train_audio_npy/' \n",
    "train_csv = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/train-not-annotated.csv' \n",
    "annotated_train_csv = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/trainval-split/trainval-annotated.csv'\n",
    "not_annotated_splt = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/trainval-split/trainval.csv'\n",
    "sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_data = pd.read_csv(annotated_train_csv)\n",
    "train_data = trainval_data[trainval_data['set'] == 'tr']\n",
    "val_data = trainval_data[trainval_data['set'] == 'val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating a class to do the extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extraction:\n",
    "  def __init__(self, train_df, val_df, window_size, overlap=0.5, npy_path=npy_path, sr=sr, n_mels=128, n_mfcc=20, n_chroma=12, n_cqt=84, hoplength=256, features=['mfcc'], normalize=True, avgpool=False):\n",
    "    \"\"\"\n",
    "    Instantiate the Extraction class to extract features.\n",
    "\n",
    "    Parameters:\n",
    "      sr (int): Sample rate of the audio files.\n",
    "      n_mfccs (int): Number of MFCCs to extract.\n",
    "      n_mels (int): Number of Mel bands to extract.\n",
    "      n_chroma (int): Number of chroma bins to use.\n",
    "      n_cqt (int): Number of CQT bins to use.\n",
    "      features (list): List of features to extract.\n",
    "        accepted features: 'mfcc', 'chroma', 'cqt', 'melspectrogram'.\n",
    "      normalize (bool): Whether to normalize the features.\n",
    "      avgpool (bool): Whether to avgpool the features.\n",
    "    \"\"\"\n",
    "    \n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.npy_path = npy_path\n",
    "    self.window_size = window_size\n",
    "    self.overlap = overlap\n",
    "    self.sr = sr\n",
    "    self.n_mels = n_mels\n",
    "    self.n_mfcc = n_mfcc\n",
    "    self.n_chroma = n_chroma\n",
    "    self.n_cqt = n_cqt\n",
    "    self.hoplength = hoplength\n",
    "\n",
    "     # confirm features have been specified\n",
    "    assert len(features) != 0, \"Must Specify At Least One Feature In The Form Of A List.\"\n",
    "    self.features = features\n",
    "\n",
    "    self.accepted_feature = ['mfcc', 'chroma', 'cqt', 'melspectrogram']\n",
    "    for feature in self.features:\n",
    "      assert feature in self.accepted_feature, f\"{feature} is not an accepted feature, only 'mfcc', 'chroma', 'cqt', 'melspectrogram' are accepted features.\"\n",
    "\n",
    "    self.normalize = normalize\n",
    "    self.avgpool = avgpool\n",
    "\n",
    "    print(f\"Train DataFrame shape: {train_df.shape}\")\n",
    "    print(f\"Validation DataFrame shape: {val_df.shape}\")\n",
    "\n",
    "    # extract train and val labels and features\n",
    "    self.train_y, self.train_features, self.train_ids = self.feature_extraction(self.train_df, window_size=self.window_size)\n",
    "    self.val_y, self.val_features, self.val_ids = self.feature_extraction(self.val_df, window_size=self.window_size)\n",
    "\n",
    "    # process the features by average pooling\n",
    "    self.train_features_2D, self.val_features_2D, self.train_features_1D, self.val_features_1D = self.process_features(self.train_features, self.val_features)\n",
    "\n",
    "\n",
    "  def normalize_audio(self, audio):\n",
    "    return (audio - np.min(audio)) / (np.max(audio) - np.min(audio))\n",
    "  \n",
    "  def generate_pink_noise(self, num_samples):\n",
    "    white_noise = np.random.randn(num_samples)\n",
    "    \n",
    "    # Apply a filter to convert white noise into pink noise (1/f noise)\n",
    "    X = np.fft.rfft(white_noise)\n",
    "    S = np.arange(1, len(X) + 1)  # Frequency scaling\n",
    "    pink_noise = np.fft.irfft(X / S)\n",
    "\n",
    "    if len(pink_noise) < num_samples:\n",
    "        # Pad with zeros if the length is less than num_samples\n",
    "        pink_noise = np.pad(pink_noise, (0, num_samples - len(pink_noise)), mode='constant')\n",
    "    elif len(pink_noise) > num_samples:\n",
    "        # Trim if necessary\n",
    "        pink_noise = pink_noise[:num_samples]\n",
    "    \n",
    "    return self.normalize_audio(pink_noise)\n",
    "  \n",
    "  def pad_with_noise(self, audio_data, window_length, window_samples):\n",
    "    current_length = librosa.get_duration(y=audio_data, sr=self.sr)\n",
    "\n",
    "    if current_length > window_length:\n",
    "        return audio_data\n",
    "    \n",
    "    target_length_samples = int(window_length * sr) \n",
    "    current_length_samples = window_samples\n",
    "    padding_length_samples = target_length_samples - current_length_samples\n",
    "\n",
    "    assert target_length_samples == (current_length_samples+padding_length_samples)\n",
    "    \n",
    "    # Generate pink noise to pad with\n",
    "    pink_noise = self.generate_pink_noise(padding_length_samples)\n",
    "    padded_audio = np.concatenate([audio_data, pink_noise])\n",
    "    # if len(padded_audio) < target_length_samples:\n",
    "    #     padded_audio = np.append(padded_audio, self.generate_pink_noise(1))\n",
    "\n",
    "    assert target_length_samples == len(padded_audio)\n",
    "    \n",
    "    return padded_audio\n",
    "  \n",
    "  def avg_pooling_keras(self, feature):\n",
    "    # Clear the previous Keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Define the input shape based on features\n",
    "    input_shape = feature.shape[1:]  # (n_mels, time_steps)\n",
    "\n",
    "    # Create the Keras model for average pooling\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    pooled = tf.keras.layers.GlobalAveragePooling1D()(inputs)\n",
    "    pooling_model = tf.keras.models.Model(inputs=inputs, outputs=pooled)\n",
    "\n",
    "    # Perform pooling using the model\n",
    "    pooled_features = pooling_model.predict(feature)\n",
    "\n",
    "    return pooled_features\n",
    "\n",
    "#-------------------------Feature Extraction---------------------------------------\n",
    "  def extract_mfcc(self, window):\n",
    "    mfcc = librosa.feature.mfcc(y=window, sr=self.sr, n_mfcc=self.n_mfcc, hop_length=self.hoplength)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(mfcc)\n",
    "    else:\n",
    "      return mfcc\n",
    "\n",
    "\n",
    "  def extract_chroma(self, window):\n",
    "    chroma = librosa.feature.chroma_stft(y=window, sr=self.sr, n_chroma=self.n_chroma, hop_length=self.hoplength)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(chroma)\n",
    "    else:\n",
    "      return chroma\n",
    "   \n",
    "\n",
    "  def extract_cqt(self, window):\n",
    "    cqt = librosa.cqt(y=window, sr=sr, hop_length=self.hoplength, n_bins=self.n_cqt)\n",
    "    cqt_db = librosa.amplitude_to_db(np.abs(cqt), ref=np.max)\n",
    "    return cqt_db\n",
    "\n",
    "  def extract_melspectrogram(self, window):\n",
    "    mel = librosa.feature.melspectrogram(y=window, sr=self.sr, n_mels=self.n_mels, hop_length=self.hoplength)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(mel_db)\n",
    "    else:\n",
    "      return mel_db\n",
    "    \n",
    "  def avgpooling(self, train_X, val_X, n_time, n_features):\n",
    "    \"\"\"\n",
    "    Average pooling the train and val features.\n",
    "\n",
    "    Parameters:\n",
    "      train_X (npy): Training feature array of shape (batch_size, n_features, n_time)\n",
    "      val_X (npy): Validation feature array of shape (batch_size, n_features, n_time)\n",
    "      n_time (int): Time axis\n",
    "      n_features (int): Feature axis\n",
    "\n",
    "    Returns:\n",
    "      train_X (npy): Avgpooled training feature array of shape (batch_size, n_features)\n",
    "      val_X (npy): Avgpooled validation feature array of shape (batch_size, n_features)\n",
    "    \"\"\"\n",
    "    # Clear the Keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Create the Keras input layer with shape (n_features, n_time)\n",
    "    input_layer = tf.keras.layers.Input(shape=(n_features, n_time))\n",
    "    \n",
    "    # Apply average pooling over the time axis (axis=-1) to reduce n_time\n",
    "    avg_pool = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1))(input_layer)\n",
    "    \n",
    "    # Build the model\n",
    "    pooling_model = tf.keras.models.Model(inputs=input_layer, outputs=avg_pool)\n",
    "\n",
    "    # Use the model to apply average pooling on the training and validation features\n",
    "    train_X = pooling_model.predict(train_X)\n",
    "    val_X = pooling_model.predict(val_X)\n",
    "\n",
    "    return train_X, val_X\n",
    "\n",
    "    \n",
    "  def process_features(self, train_features_dict, val_features_dict):\n",
    "    train_copy = train_features_dict.copy()\n",
    "    val_copy = val_features_dict.copy()\n",
    "    for each in train_copy.keys():\n",
    "      \n",
    "      if each == 'mfcc':\n",
    "        n_features=self.n_mfcc\n",
    "      elif each == 'chroma':\n",
    "        n_features=self.n_chroma\n",
    "      elif each == 'cqt':\n",
    "        n_features=self.n_cqt\n",
    "      elif each == 'melspectrogram':\n",
    "        n_features=self.n_mels\n",
    "      \n",
    "      train_feature = train_copy[each]\n",
    "      val_feature = val_copy[each]\n",
    "\n",
    "      if self.avgpool:\n",
    "        train_copy[each], val_copy[each] = self.avgpooling(train_feature, val_feature, n_time=train_feature.shape[2], n_features=n_features)\n",
    "      else:\n",
    "        train_copy[each], val_copy[each] = train_copy[each], val_copy[each]\n",
    "    \n",
    "    return train_features_dict, val_features_dict, train_copy, val_copy\n",
    "      \n",
    "\n",
    "  def feature_extraction(self, dataframe, window_size):\n",
    "    y = [] # To hold the labels\n",
    "    ids = []\n",
    "    features_dict = {item: [] for item in self.features} # Create a key for each feature listed\n",
    "    print(f\"Number of rows in dataframe: {len(dataframe)}\")\n",
    "    for _, row in tqdm(dataframe.iterrows(), desc=\"Processing data\", total=len(dataframe)):\n",
    "          label = row['species']\n",
    "          file_path = os.path.join(self.npy_path, row['filename_npy'])\n",
    "          id = row['audio_name']\n",
    "          start = row['start']\n",
    "          end = row['end']\n",
    "\n",
    "          # print(f\"Processing file: {file_path}\")\n",
    "\n",
    "          try:\n",
    "            \n",
    "              audio = np.load(file_path)\n",
    "          except FileNotFoundError:\n",
    "              print(f\"File not found: {file_path}\")\n",
    "              continue\n",
    "\n",
    "\n",
    "          start = int(start * sr)\n",
    "          end = int(end * sr)+512\n",
    "\n",
    "\n",
    "\n",
    "          if end > len(audio):\n",
    "             end = len(audio)\n",
    "\n",
    "          sample = audio[start:end]\n",
    "\n",
    "          if len(sample) < 512:\n",
    "                continue\n",
    "\n",
    "          sample = self.normalize_audio(sample)\n",
    "\n",
    "          sample = self.pad_with_noise(sample, window_length=self.window_size, window_samples=len(sample))\n",
    "          # print(len(sample))\n",
    "\n",
    "          window_samples = int(window_size * self.sr)\n",
    "          hop_samples = int(window_samples * (1 - self.overlap))  # For overlapping\n",
    "\n",
    "          # Break the audio into windows with the specified overlap\n",
    "          audio_windows = librosa.util.frame(sample, frame_length=window_samples, hop_length=hop_samples).T\n",
    "          \n",
    "          \n",
    "          # display(label)\n",
    "          \n",
    "          for _, window in enumerate(audio_windows):\n",
    "              \n",
    "              y.append(label)\n",
    "              ids.append(id)\n",
    "\n",
    "              if len(window) < window_samples:\n",
    "                  if len(window) < 512*2:\n",
    "                     continue\n",
    "                  else:\n",
    "                      window = self.pad_with_noise(window, window_length=window_size)\n",
    "              \n",
    "              # Feature Extraction FR --------------------------------------------------------------------\n",
    "              # dynatically call the extract_x function to extract the listed features\n",
    "              for feature in self.features:\n",
    "                extract = f\"extract_{feature}\"\n",
    "                if hasattr(self, extract) and callable(func := getattr(self, extract)):\n",
    "                  features_dict[feature].append(func(window))\n",
    "\n",
    "          # cast lists to np arrays\n",
    "    for each in features_dict.keys():\n",
    "              features_dict[each] = np.array(features_dict[each])\n",
    "\n",
    "    y = np.array(y)\n",
    "    ids = np.array(ids)\n",
    "\n",
    "          # If not using average pooling, return resized features\n",
    "    return y, features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Window Size = 3s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc', 'chroma', 'cqt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (485, 6)\n",
      "Validation DataFrame shape: (130, 6)\n",
      "Number of rows in dataframe: 485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 485/485 [08:21<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataframe: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 130/130 [01:41<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step\n"
     ]
    }
   ],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=3,\n",
    "                      features=features_list,\n",
    "                      avgpool=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10981,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10981, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mfcc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10981, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'chroma'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10981, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rms'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10981, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_y = features.train_y\n",
    "val_y = features.val_y\n",
    "\n",
    "display(train_y.shape)\n",
    "display(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avgpooled Features\n",
    "train_features_1D = features.train_features_1D\n",
    "for key in train_features_1D.keys():\n",
    "  display(key)\n",
    "  display(train_features_1D[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avgpooled Features\n",
    "val_features_1D = features.val_features_1D\n",
    "for key in val_features_1D.keys():\n",
    "  display(key)\n",
    "  display(val_features_1D[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not avgpooled Features\n",
    "train_features_2D = features.train_features_2D\n",
    "for key in train_features_2D.keys():\n",
    "  display(key)\n",
    "  display(train_features_2D[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not avgpooled Features\n",
    "val_features_2D = features.val_features_2D\n",
    "for key in val_features_2D.keys():\n",
    "  display(key)\n",
    "  display(val_features_2D[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = features.train_ids\n",
    "val_ids = features.val_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes for [0, 1, 2]: ['Acrocephalus arundinaceus', 'Acrocephalus melanopogon', 'Acrocephalus scirpaceus']\n",
      "Encoded training labels: [1 1 1 ... 5 5 5]\n",
      "Encoded validation labels: [1 1 1 ... 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg Pooled\n",
    "\n",
    "train_features_1D['label'] = train_y_encoded\n",
    "val_features_1D['label'] = val_y_encoded\n",
    "\n",
    "train_features_1D['id'] = train_ids\n",
    "val_features_1D['id'] = val_ids\n",
    "\n",
    "# Not Avg Pooled\n",
    "\n",
    "train_features_2D['label'] = train_y_encoded\n",
    "val_features_2D['label'] = val_y_encoded\n",
    "\n",
    "train_features_2D['id'] = train_ids\n",
    "val_features_2D['id'] = val_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict_1D = {'train': train_features_1D, 'val': val_features_1D}\n",
    "merged_dict_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'melspectrogram': array([[1.7294491e-05, 1.8239583e-05, 1.9485902e-05, ..., 5.1940111e-07,\n",
       "          3.2287385e-08, 2.7940120e-08],\n",
       "         [7.9314253e-07, 8.0714307e-07, 8.3096978e-07, ..., 1.3027967e-06,\n",
       "          8.4759665e-07, 8.0172282e-07],\n",
       "         [3.0612518e-06, 3.0607123e-06, 3.0592107e-06, ..., 6.0072955e-07,\n",
       "          3.6999687e-08, 1.4126979e-08],\n",
       "         ...,\n",
       "         [1.0815166e-06, 1.0910663e-06, 1.1071655e-06, ..., 4.2367597e-07,\n",
       "          1.3173792e-07, 1.2475495e-07],\n",
       "         [2.1907644e-07, 2.7223422e-07, 3.6665881e-07, ..., 5.7446897e-07,\n",
       "          1.8625977e-07, 1.7997159e-07],\n",
       "         [2.4198832e-06, 2.6966893e-06, 3.1864115e-06, ..., 1.2659899e-05,\n",
       "          2.3157411e-07, 2.2612821e-07]], dtype=float32),\n",
       "  'mfcc': array([[-1.0000000e+00, -2.3626368e-01, -5.0428110e-01, ...,\n",
       "           5.1737577e-03,  1.1148715e-02,  3.4610374e-04],\n",
       "         [-1.0000000e+00, -2.4848318e-01, -4.7058651e-01, ...,\n",
       "           2.9826174e-03,  9.7121680e-03, -5.3395964e-03],\n",
       "         [-1.0000000e+00, -2.1472941e-01, -3.9474082e-01, ...,\n",
       "          -3.8874066e-03,  1.6939165e-02, -8.0259237e-03],\n",
       "         ...,\n",
       "         [-1.0000000e+00, -4.8605792e-02, -5.0560749e-01, ...,\n",
       "          -1.1745107e-02,  4.4932691e-03, -2.8505510e-02],\n",
       "         [-1.0000000e+00, -2.8515840e-02, -3.7700239e-01, ...,\n",
       "          -1.1284011e-02,  9.0192836e-03, -2.1381233e-02],\n",
       "         [-1.0000000e+00, -4.6963759e-02, -3.1230685e-01, ...,\n",
       "          -1.1913958e-03,  5.6325276e-03, -1.4546473e-02]], dtype=float32),\n",
       "  'chroma': array([[0.46446815, 0.49344763, 0.272792  , ..., 0.33641616, 0.35591307,\n",
       "          0.4465878 ],\n",
       "         [0.4498349 , 0.4656876 , 0.2713559 , ..., 0.31607577, 0.35203218,\n",
       "          0.42755732],\n",
       "         [0.36486772, 0.39883375, 0.33119655, ..., 0.30271965, 0.37420923,\n",
       "          0.34706914],\n",
       "         ...,\n",
       "         [0.49500066, 0.43938106, 0.4447228 , ..., 0.31922016, 0.37807077,\n",
       "          0.47952107],\n",
       "         [0.6208546 , 0.57111466, 0.55245966, ..., 0.4631326 , 0.49097157,\n",
       "          0.58401203],\n",
       "         [0.55163413, 0.57258   , 0.57687557, ..., 0.45064372, 0.49031565,\n",
       "          0.5414636 ]], dtype=float32),\n",
       "  'rms': array([[0.03240787],\n",
       "         [0.03098402],\n",
       "         [0.02741831],\n",
       "         ...,\n",
       "         [0.0192934 ],\n",
       "         [0.00846047],\n",
       "         [0.00208637]], dtype=float32),\n",
       "  'label': array([1, 1, 1, ..., 5, 5, 5])},\n",
       " 'val': {'melspectrogram': array([[3.75477839e-06, 3.76116282e-06, 3.77205765e-06, ...,\n",
       "          5.65175878e-06, 5.06358674e-06, 4.80833251e-06],\n",
       "         [3.40994302e-06, 3.41521968e-06, 3.42404178e-06, ...,\n",
       "          3.41328644e-07, 3.00770182e-07, 2.80889481e-07],\n",
       "         [8.39739641e-07, 8.41037206e-07, 8.43205953e-07, ...,\n",
       "          1.24349810e-06, 1.14588988e-06, 1.09064842e-06],\n",
       "         ...,\n",
       "         [2.56626549e-07, 2.66493231e-07, 2.83625809e-07, ...,\n",
       "          4.07689697e-07, 3.82143469e-07, 3.68111017e-07],\n",
       "         [1.88428730e-05, 1.89519051e-05, 1.91351082e-05, ...,\n",
       "          4.76290410e-07, 4.48368240e-07, 4.33282480e-07],\n",
       "         [1.29688988e-05, 1.31203005e-05, 1.33786443e-05, ...,\n",
       "          6.97713119e-07, 6.52227982e-07, 6.30009254e-07]], dtype=float32),\n",
       "  'mfcc': array([[-1.        , -0.21453853, -0.38537365, ...,  0.00559846,\n",
       "           0.00889489, -0.01819588],\n",
       "         [-1.        , -0.25982228, -0.3988581 , ...,  0.01121113,\n",
       "           0.01036923, -0.0243206 ],\n",
       "         [-1.        , -0.262715  , -0.3744428 , ...,  0.00848942,\n",
       "           0.01277183, -0.02345961],\n",
       "         ...,\n",
       "         [-1.        , -0.06231845, -0.59439707, ..., -0.01251288,\n",
       "          -0.00654217, -0.02056992],\n",
       "         [-1.        , -0.06773086, -0.5973017 , ..., -0.01139232,\n",
       "          -0.01083555, -0.0206809 ],\n",
       "         [-1.        , -0.08160123, -0.6311919 , ..., -0.01181426,\n",
       "          -0.01046068, -0.01674579]], dtype=float32),\n",
       "  'chroma': array([[0.28993642, 0.14844978, 0.25089073, ..., 0.27022564, 0.47226036,\n",
       "          0.50559175],\n",
       "         [0.28735775, 0.13351597, 0.1746383 , ..., 0.25527453, 0.54639953,\n",
       "          0.5476516 ],\n",
       "         [0.24501   , 0.13009955, 0.16586517, ..., 0.2793253 , 0.6059031 ,\n",
       "          0.54991734],\n",
       "         ...,\n",
       "         [0.38608274, 0.30369505, 0.2996028 , ..., 0.5470512 , 0.5838331 ,\n",
       "          0.4617382 ],\n",
       "         [0.36054567, 0.24516311, 0.23104598, ..., 0.50654596, 0.52629155,\n",
       "          0.5030136 ],\n",
       "         [0.2807677 , 0.22412933, 0.3575237 , ..., 0.494704  , 0.60032076,\n",
       "          0.4600499 ]], dtype=float32),\n",
       "  'rms': array([[0.03921141],\n",
       "         [0.04844475],\n",
       "         [0.05661466],\n",
       "         ...,\n",
       "         [0.02227492],\n",
       "         [0.02077173],\n",
       "         [0.02604896]], dtype=float32),\n",
       "  'label': array([1, 1, 1, ..., 5, 5, 5])}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_dict_2D = {'train': train_features_2D, 'val': val_features_2D}\n",
    "merged_dict_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avrg Pooled\n",
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Final-Version-Of-Bird-Classification-Project/feature-extraction/Annotated/Regular/AveragePooled/split_features_3s_all_1D.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict_1D, file)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avrg Pooled\n",
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Final-Version-Of-Bird-Classification-Project/feature-extraction/Annotated/Regular/NotAveragePooled/split_features_3s_all_2D.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict_2D, file)\n",
    "del file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Window Size = 1s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc', 'chroma', 'cqt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (485, 6)\n",
      "Validation DataFrame shape: (130, 6)\n",
      "Number of rows in dataframe: 485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 485/485 [08:21<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataframe: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 130/130 [01:41<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step\n"
     ]
    }
   ],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=1,\n",
    "                      features=features_list,\n",
    "                      avgpool=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10981,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10981, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mfcc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10981, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'chroma'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10981, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rms'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10981, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_y = features.train_y\n",
    "val_y = features.val_y\n",
    "\n",
    "display(train_y.shape)\n",
    "display(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avgpooled Features\n",
    "train_features_1D = features.train_features_1D\n",
    "for key in train_features_1D.keys():\n",
    "  display(key)\n",
    "  display(train_features_1D[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avgpooled Features\n",
    "val_features_1D = features.val_features_1D\n",
    "for key in val_features_1D.keys():\n",
    "  display(key)\n",
    "  display(val_features_1D[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not avgpooled Features\n",
    "train_features_2D = features.train_features_2D\n",
    "for key in train_features_2D.keys():\n",
    "  display(key)\n",
    "  display(train_features_2D[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not avgpooled Features\n",
    "val_features_2D = features.val_features_2D\n",
    "for key in val_features_2D.keys():\n",
    "  display(key)\n",
    "  display(val_features_2D[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = features.train_ids\n",
    "val_ids = features.val_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes for [0, 1, 2]: ['Acrocephalus arundinaceus', 'Acrocephalus melanopogon', 'Acrocephalus scirpaceus']\n",
      "Encoded training labels: [1 1 1 ... 5 5 5]\n",
      "Encoded validation labels: [1 1 1 ... 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg Pooled\n",
    "\n",
    "train_features_1D['label'] = train_y_encoded\n",
    "val_features_1D['label'] = val_y_encoded\n",
    "\n",
    "train_features_1D['id'] = train_ids\n",
    "val_features_1D['id'] = val_ids\n",
    "\n",
    "# Not Avg Pooled\n",
    "\n",
    "train_features_2D['label'] = train_y_encoded\n",
    "val_features_2D['label'] = val_y_encoded\n",
    "\n",
    "train_features_2D['id'] = train_ids\n",
    "val_features_2D['id'] = val_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict_1D = {'train': train_features_1D, 'val': val_features_1D}\n",
    "merged_dict_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'melspectrogram': array([[1.7294491e-05, 1.8239583e-05, 1.9485902e-05, ..., 5.1940111e-07,\n",
       "          3.2287385e-08, 2.7940120e-08],\n",
       "         [7.9314253e-07, 8.0714307e-07, 8.3096978e-07, ..., 1.3027967e-06,\n",
       "          8.4759665e-07, 8.0172282e-07],\n",
       "         [3.0612518e-06, 3.0607123e-06, 3.0592107e-06, ..., 6.0072955e-07,\n",
       "          3.6999687e-08, 1.4126979e-08],\n",
       "         ...,\n",
       "         [1.0815166e-06, 1.0910663e-06, 1.1071655e-06, ..., 4.2367597e-07,\n",
       "          1.3173792e-07, 1.2475495e-07],\n",
       "         [2.1907644e-07, 2.7223422e-07, 3.6665881e-07, ..., 5.7446897e-07,\n",
       "          1.8625977e-07, 1.7997159e-07],\n",
       "         [2.4198832e-06, 2.6966893e-06, 3.1864115e-06, ..., 1.2659899e-05,\n",
       "          2.3157411e-07, 2.2612821e-07]], dtype=float32),\n",
       "  'mfcc': array([[-1.0000000e+00, -2.3626368e-01, -5.0428110e-01, ...,\n",
       "           5.1737577e-03,  1.1148715e-02,  3.4610374e-04],\n",
       "         [-1.0000000e+00, -2.4848318e-01, -4.7058651e-01, ...,\n",
       "           2.9826174e-03,  9.7121680e-03, -5.3395964e-03],\n",
       "         [-1.0000000e+00, -2.1472941e-01, -3.9474082e-01, ...,\n",
       "          -3.8874066e-03,  1.6939165e-02, -8.0259237e-03],\n",
       "         ...,\n",
       "         [-1.0000000e+00, -4.8605792e-02, -5.0560749e-01, ...,\n",
       "          -1.1745107e-02,  4.4932691e-03, -2.8505510e-02],\n",
       "         [-1.0000000e+00, -2.8515840e-02, -3.7700239e-01, ...,\n",
       "          -1.1284011e-02,  9.0192836e-03, -2.1381233e-02],\n",
       "         [-1.0000000e+00, -4.6963759e-02, -3.1230685e-01, ...,\n",
       "          -1.1913958e-03,  5.6325276e-03, -1.4546473e-02]], dtype=float32),\n",
       "  'chroma': array([[0.46446815, 0.49344763, 0.272792  , ..., 0.33641616, 0.35591307,\n",
       "          0.4465878 ],\n",
       "         [0.4498349 , 0.4656876 , 0.2713559 , ..., 0.31607577, 0.35203218,\n",
       "          0.42755732],\n",
       "         [0.36486772, 0.39883375, 0.33119655, ..., 0.30271965, 0.37420923,\n",
       "          0.34706914],\n",
       "         ...,\n",
       "         [0.49500066, 0.43938106, 0.4447228 , ..., 0.31922016, 0.37807077,\n",
       "          0.47952107],\n",
       "         [0.6208546 , 0.57111466, 0.55245966, ..., 0.4631326 , 0.49097157,\n",
       "          0.58401203],\n",
       "         [0.55163413, 0.57258   , 0.57687557, ..., 0.45064372, 0.49031565,\n",
       "          0.5414636 ]], dtype=float32),\n",
       "  'rms': array([[0.03240787],\n",
       "         [0.03098402],\n",
       "         [0.02741831],\n",
       "         ...,\n",
       "         [0.0192934 ],\n",
       "         [0.00846047],\n",
       "         [0.00208637]], dtype=float32),\n",
       "  'label': array([1, 1, 1, ..., 5, 5, 5])},\n",
       " 'val': {'melspectrogram': array([[3.75477839e-06, 3.76116282e-06, 3.77205765e-06, ...,\n",
       "          5.65175878e-06, 5.06358674e-06, 4.80833251e-06],\n",
       "         [3.40994302e-06, 3.41521968e-06, 3.42404178e-06, ...,\n",
       "          3.41328644e-07, 3.00770182e-07, 2.80889481e-07],\n",
       "         [8.39739641e-07, 8.41037206e-07, 8.43205953e-07, ...,\n",
       "          1.24349810e-06, 1.14588988e-06, 1.09064842e-06],\n",
       "         ...,\n",
       "         [2.56626549e-07, 2.66493231e-07, 2.83625809e-07, ...,\n",
       "          4.07689697e-07, 3.82143469e-07, 3.68111017e-07],\n",
       "         [1.88428730e-05, 1.89519051e-05, 1.91351082e-05, ...,\n",
       "          4.76290410e-07, 4.48368240e-07, 4.33282480e-07],\n",
       "         [1.29688988e-05, 1.31203005e-05, 1.33786443e-05, ...,\n",
       "          6.97713119e-07, 6.52227982e-07, 6.30009254e-07]], dtype=float32),\n",
       "  'mfcc': array([[-1.        , -0.21453853, -0.38537365, ...,  0.00559846,\n",
       "           0.00889489, -0.01819588],\n",
       "         [-1.        , -0.25982228, -0.3988581 , ...,  0.01121113,\n",
       "           0.01036923, -0.0243206 ],\n",
       "         [-1.        , -0.262715  , -0.3744428 , ...,  0.00848942,\n",
       "           0.01277183, -0.02345961],\n",
       "         ...,\n",
       "         [-1.        , -0.06231845, -0.59439707, ..., -0.01251288,\n",
       "          -0.00654217, -0.02056992],\n",
       "         [-1.        , -0.06773086, -0.5973017 , ..., -0.01139232,\n",
       "          -0.01083555, -0.0206809 ],\n",
       "         [-1.        , -0.08160123, -0.6311919 , ..., -0.01181426,\n",
       "          -0.01046068, -0.01674579]], dtype=float32),\n",
       "  'chroma': array([[0.28993642, 0.14844978, 0.25089073, ..., 0.27022564, 0.47226036,\n",
       "          0.50559175],\n",
       "         [0.28735775, 0.13351597, 0.1746383 , ..., 0.25527453, 0.54639953,\n",
       "          0.5476516 ],\n",
       "         [0.24501   , 0.13009955, 0.16586517, ..., 0.2793253 , 0.6059031 ,\n",
       "          0.54991734],\n",
       "         ...,\n",
       "         [0.38608274, 0.30369505, 0.2996028 , ..., 0.5470512 , 0.5838331 ,\n",
       "          0.4617382 ],\n",
       "         [0.36054567, 0.24516311, 0.23104598, ..., 0.50654596, 0.52629155,\n",
       "          0.5030136 ],\n",
       "         [0.2807677 , 0.22412933, 0.3575237 , ..., 0.494704  , 0.60032076,\n",
       "          0.4600499 ]], dtype=float32),\n",
       "  'rms': array([[0.03921141],\n",
       "         [0.04844475],\n",
       "         [0.05661466],\n",
       "         ...,\n",
       "         [0.02227492],\n",
       "         [0.02077173],\n",
       "         [0.02604896]], dtype=float32),\n",
       "  'label': array([1, 1, 1, ..., 5, 5, 5])}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_dict_2D = {'train': train_features_2D, 'val': val_features_2D}\n",
    "merged_dict_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avrg Pooled\n",
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Final-Version-Of-Bird-Classification-Project/feature-extraction/Annotated/Regular/AveragePooled/split_features_1s_all_1D.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict_1D, file)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avrg Pooled\n",
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Final-Version-Of-Bird-Classification-Project/feature-extraction/Annotated/Regular/NotAveragePooled/split_features_1s_all_2D.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict_2D, file)\n",
    "del file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
