{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZbjVupctQds"
      },
      "source": [
        "# **Convolutional Neural Network**\n",
        "**Starting parameters**:\n",
        "\n",
        "- Number of epochs: 100\n",
        "- Learning rate: 0.0005\n",
        "- Layers: [64, 32, 32]\n",
        "- Dropout: 0.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIczGFG3tPW3",
        "outputId": "22de3645-5770-40d8-c6c9-9b7839417018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fvbc5i78vXj1"
      },
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "# For preprocessing\n",
        "import tensorflow as tf\n",
        "\n",
        "# For modeling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Operational\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fXPOIwALvjaP"
      },
      "outputs": [],
      "source": [
        "pkl_path = '/content/drive/My Drive/Final-Year-Project/Dataset/Final-Version-of-Bird-Classification-Project/feature-extraction/NotAnnotated/Regular/NotAveragePooled/split_features_6s_all_2D.pkl'\n",
        "\n",
        "# Load the pickle file\n",
        "with open(pkl_path, 'rb') as file:\n",
        "    data = pickle.load(file)\n",
        "del file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PoAVhlX1xS-R"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/My Drive/Final-Year-Project/Final-Version-of-Bird-Classification-Project/a. Imbalanced-Data/3. Training/Figures/CNN/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "enVU1ttOvoId"
      },
      "outputs": [],
      "source": [
        "train_data = data['train'].copy()\n",
        "val_data = data['val'].copy()\n",
        "del data\n",
        "\n",
        "train_labels = train_data['label'].copy()\n",
        "temp = train_data.copy()\n",
        "del temp['label']\n",
        "tr_features = temp\n",
        "\n",
        "val_labels = val_data['label'].copy()\n",
        "temp = val_data.copy()\n",
        "del temp['label']\n",
        "v_features = temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSALyZ_ov3Ar"
      },
      "source": [
        "## **Shuffling Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l56DzbZJvtSx"
      },
      "outputs": [],
      "source": [
        "def shuffle_data(input_label, input_features):\n",
        "  input_len = len(input_label)\n",
        "  np.random.seed(1826)\n",
        "  input_indices = np.random.permutation(input_len)\n",
        "  input_features = {key: np.array([input_features[key][i] for i in input_indices]) for key in input_features} # dictionary comprehension\n",
        "  input_label = np.array([input_label[i] for i in input_indices])\n",
        "\n",
        "  return input_label, input_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BADXTyNiv7lW"
      },
      "outputs": [],
      "source": [
        "train_y, train_features = shuffle_data(train_labels, tr_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mxUYFNO0v-Bg"
      },
      "outputs": [],
      "source": [
        "val_y, val_features = shuffle_data(val_labels, v_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6W0uaq-wCfJ"
      },
      "source": [
        "## **CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hxtoeAK_v-nu"
      },
      "outputs": [],
      "source": [
        "def build_model(audio_features,\n",
        "                learning_rate=0.00005):\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  # set audio features input layer\n",
        "  inputs = tf.keras.layers.Input(shape=(audio_features.shape[1],audio_features.shape[2],audio_features.shape[3]), name='Audio_Features')\n",
        "\n",
        "\n",
        "  features = tf.keras.layers.Conv2D(\n",
        "              filters=64,\n",
        "              kernel_size=(5,5),\n",
        "              strides=(1,1),\n",
        "              padding='same',\n",
        "              data_format='channels_last',\n",
        "              name='conv_1',\n",
        "              activation='relu',\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(0.15))(inputs)\n",
        "\n",
        "  features = tf.keras.layers.MaxPool2D(pool_size=(2,2), name='pool_1')(features)\n",
        "\n",
        "\n",
        "  features = tf.keras.layers.Conv2D(\n",
        "              filters=32,\n",
        "              kernel_size=(5,5),\n",
        "              strides=(1,1),\n",
        "              padding='same',\n",
        "              name='conv_2',\n",
        "              activation='relu',\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(0.15))(features)\n",
        "\n",
        "  features = tf.keras.layers.MaxPool2D(pool_size=(2,2), name='pool_2')(features)\n",
        "\n",
        "\n",
        "  features = tf.keras.layers.Conv2D(\n",
        "              filters=32,\n",
        "              kernel_size=(5,5),\n",
        "              strides=(1,1),\n",
        "              padding='same',\n",
        "              name='conv_3',\n",
        "              activation='relu',\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(0.15))(features)\n",
        "\n",
        "  features = tf.keras.layers.BatchNormalization()(features)\n",
        "  features = tf.keras.layers.MaxPool2D(pool_size=(2,2), name='pool_3')(features)\n",
        "\n",
        "  # add a fully connected layer (need to flatten the output of the previous layers first)\n",
        "  features = tf.keras.layers.Flatten()(features)\n",
        "\n",
        "  features = tf.keras.layers.Dense(\n",
        "      units=512,\n",
        "      name='fc_1',\n",
        "      activation='relu')(features)\n",
        "\n",
        "  # add dropout layer\n",
        "  features = tf.keras.layers.Dropout(rate=0.3)(features)\n",
        "\n",
        "  # add the last fully connected layer\n",
        "  # this last layer sets the activation function to \"None\" in order to output the logits\n",
        "  # note that passing activation = \"softmax\" will return class memembership probabilities\n",
        "  outputs = tf.keras.layers.Dense(\n",
        "      units=20,\n",
        "      name='fc_2',\n",
        "      activation='softmax')(features)\n",
        "\n",
        "  # build model and print summary\n",
        "  model = tf.keras.Model(inputs=[inputs],\n",
        "                          outputs=outputs,\n",
        "                          name='Birds')\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  # compile model\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'],\n",
        "              weighted_metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_q4T8A9kwn_w"
      },
      "outputs": [],
      "source": [
        "def visualize(model_history, name):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "    # Visualize the loss\n",
        "    axes[0].plot(model_history.history['loss'], color='red', label='Training Loss')\n",
        "    axes[0].plot(model_history.history['val_loss'], color='blue', label='Validation Loss')\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Loss', fontsize=12)\n",
        "    axes[0].set_title('Loss Progression', fontsize=14)\n",
        "    axes[0].grid(True)\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Visualize the accuracy\n",
        "    axes[1].plot(model_history.history['accuracy'], color='green', label='Training Accuracy')\n",
        "    axes[1].plot(model_history.history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "    axes[1].set_title('Accuracy Progression', fontsize=14)\n",
        "    axes[1].grid(True)\n",
        "    axes[1].legend()\n",
        "\n",
        "    plt.savefig(f'{path+name}_6s_model_training_history_2D.pdf')\n",
        "\n",
        "    # Fine-tune layout and display the plots\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FQ6ySd5FzwJo"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(val_y, val_yhat, val_yhat_result, num_classes=20):\n",
        "\n",
        "    print('Validation classification Report \\n')\n",
        "    print(classification_report(val_y, val_yhat_result))\n",
        "\n",
        "    # Calculate AUC for multiclass classification using 'ovr' and 'weighted' average\n",
        "    auc_score = roc_auc_score(val_y, val_yhat, multi_class='ovr', average='weighted')\n",
        "    print(f'AUC Score: {auc_score}')\n",
        "\n",
        "    # Calculate F1-score with 'weighted' average for imbalanced dataset\n",
        "    f1 = f1_score(val_y, val_yhat_result, average='weighted')\n",
        "    print(f'F1 Score (Weighted): {f1}')\n",
        "\n",
        "    val_score = {'f1': f1, 'auc': auc_score}\n",
        "\n",
        "    return val_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tile_and_crop(feature, target_size):\n",
        "    tiled = np.tile(feature, (1, target_size // feature.shape[1] + 1, 1))\n",
        "    return tiled[:, :target_size, :]"
      ],
      "metadata": {
        "id": "47vW1YbuYIIl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DObv-Sqeyb0G"
      },
      "outputs": [],
      "source": [
        "train_results = {}\n",
        "val_results = {}\n",
        "\n",
        "val_scores = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-hlTtXpy360"
      },
      "source": [
        "### With All Features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train features\n",
        "target_size = 128\n",
        "mfcc_tiled = tile_and_crop(train_features['mfcc'], target_size)\n",
        "cqt_tiled = tile_and_crop(train_features['cqt'], target_size)\n",
        "chroma_tiled = tile_and_crop(train_features['chroma'], target_size)\n",
        "\n",
        "training_features = np.stack((train_features['melspectrogram'], mfcc_tiled, chroma_tiled, cqt_tiled), axis=-1)\n",
        "print(training_features.shape)"
      ],
      "metadata": {
        "id": "Nsjck8K5YPSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Features\n",
        "target_size = 128\n",
        "mfcc_tiled = tile_and_crop(val_features['mfcc'], target_size)\n",
        "cqt_tiled = tile_and_crop(val_features['cqt'], target_size)\n",
        "chroma_tiled = tile_and_crop(val_features['chroma'], target_size)\n",
        "\n",
        "validation_features = np.stack((val_features['melspectrogram'], mfcc_tiled, chroma_tiled, cqt_tiled), axis=-1)\n",
        "print(validation_features.shape)"
      ],
      "metadata": {
        "id": "YkVMNm9IYWA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOVKae0_zB-q"
      },
      "outputs": [],
      "source": [
        "model = build_model(training_features)\n",
        "\n",
        "history = model.fit(\n",
        "    x=training_features,\n",
        "    y=train_y,\n",
        "    epochs=100,\n",
        "    validation_data=(\n",
        "        validation_features,\n",
        "        val_y,\n",
        "    ),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyGOcWZGzLkg"
      },
      "outputs": [],
      "source": [
        "visualize(history, 'all_features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH1TokYZzXAO"
      },
      "outputs": [],
      "source": [
        "train_yhat = model.predict(training_features)\n",
        "train_yhat_result = np.argmax(train_yhat, axis=-1)\n",
        "train_results['all_features'] = model.evaluate(training_features, train_y)[-1]\n",
        "\n",
        "val_yhat = model.predict(validation_features)\n",
        "val_yhat_result = np.argmax(val_yhat, axis=-1)\n",
        "val_results['all_features'] = model.evaluate(validation_features, val_y)[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiS_Cf1wzdaX"
      },
      "outputs": [],
      "source": [
        "val_scores['all_features'] = evaluate_model(val_y=val_y, val_yhat=val_yhat, val_yhat_result=val_yhat_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdDIuhtw019E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt9hAfOd1pnO"
      },
      "source": [
        "### Mel Spectrogram and Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8KM5tfw1pnO"
      },
      "outputs": [],
      "source": [
        "# Train features\n",
        "target_size = 128\n",
        "chroma_tiled = tile_and_crop(train_features['chroma'], target_size)\n",
        "\n",
        "training_features = np.stack((train_features['melspectrogram'],  chroma_tiled), axis=-1)\n",
        "print(training_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMJdKrh81pnP"
      },
      "outputs": [],
      "source": [
        "# Validation Features\n",
        "target_size = 128\n",
        "chroma_tiled = tile_and_crop(val_features['chroma'], target_size)\n",
        "\n",
        "validation_features = np.stack((val_features['melspectrogram'],  chroma_tiled), axis=-1)\n",
        "print(validation_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENX_W2qL1pnP"
      },
      "outputs": [],
      "source": [
        "model = build_model(training_features)\n",
        "\n",
        "history = model.fit(\n",
        "    x=training_features,\n",
        "    y=train_y,\n",
        "    epochs=100,\n",
        "    validation_data=(\n",
        "        validation_features,\n",
        "        val_y,\n",
        "    ),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41Spn4T51pnP"
      },
      "outputs": [],
      "source": [
        "visualize(history, 'melspectrogram_chroma')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laEEYNuq1pnP"
      },
      "outputs": [],
      "source": [
        "train_yhat = model.predict(training_features)\n",
        "train_yhat_result = np.argmax(train_yhat, axis=-1)\n",
        "train_results['melspectrogram_chroma'] = model.evaluate(training_features, train_y)[-1]\n",
        "\n",
        "val_yhat = model.predict(validation_features)\n",
        "val_yhat_result = np.argmax(val_yhat, axis=-1)\n",
        "val_results['melspectrogram_chroma'] = model.evaluate(validation_features, val_y)[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQsqbxrT1pnP"
      },
      "outputs": [],
      "source": [
        "val_scores['melspectrogram_chroma'] = evaluate_model(val_y=val_y, val_yhat=val_yhat, val_yhat_result=val_yhat_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W06qAtR1pnP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4lftzxy1Qax"
      },
      "source": [
        "### With Mel Spectrogram, MFCCs and Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxXJ9f2d1Qax"
      },
      "outputs": [],
      "source": [
        "# Train features\n",
        "target_size = 128\n",
        "mfcc_tiled = tile_and_crop(train_features['mfcc'], target_size)\n",
        "chroma_tiled = tile_and_crop(train_features['chroma'], target_size)\n",
        "\n",
        "training_features = np.stack((train_features['melspectrogram'], mfcc_tiled, chroma_tiled), axis=-1)\n",
        "print(training_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7a8E2je1Qax"
      },
      "outputs": [],
      "source": [
        "# Validation Features\n",
        "target_size = 128\n",
        "mfcc_tiled = tile_and_crop(val_features['mfcc'], target_size)\n",
        "chroma_tiled = tile_and_crop(val_features['chroma'], target_size)\n",
        "\n",
        "validation_features = np.stack((val_features['melspectrogram'], mfcc_tiled, chroma_tiled), axis=-1)\n",
        "print(validation_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn_2p1QN1Qax"
      },
      "outputs": [],
      "source": [
        "model = build_model(training_features)\n",
        "\n",
        "history = model.fit(\n",
        "    x=training_features,\n",
        "    y=train_y,\n",
        "    epochs=100,\n",
        "    validation_data=(\n",
        "        validation_features,\n",
        "        val_y,\n",
        "    ),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmfoULEj1Qax"
      },
      "outputs": [],
      "source": [
        "visualize(history, 'melspectrogram_chroma_mfcc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usP8vZzt1Qax"
      },
      "outputs": [],
      "source": [
        "train_yhat = model.predict(training_features)\n",
        "train_yhat_result = np.argmax(train_yhat, axis=-1)\n",
        "train_results['melspectrogram_chroma_mfcc'] = model.evaluate(training_features, train_y)[-1]\n",
        "\n",
        "val_yhat = model.predict(validation_features)\n",
        "val_yhat_result = np.argmax(val_yhat, axis=-1)\n",
        "val_results['melspectrogram_chroma_mfcc'] = model.evaluate(validation_features, val_y)[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2V-Ga_t1Qay"
      },
      "outputs": [],
      "source": [
        "val_scores['melspectrogram_chroma_mfcc'] = evaluate_model(val_y=val_y, val_yhat=val_yhat, val_yhat_result=val_yhat_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PziaOMkc2DgW"
      },
      "source": [
        "### With Mel Spectrogram and MFCCs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB2jtaj52DgW"
      },
      "outputs": [],
      "source": [
        "# Train features\n",
        "training_features = np.expand_dims(train_features['melspectrogram'], axis=-1)\n",
        "print(training_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNWboY3f2DgW"
      },
      "outputs": [],
      "source": [
        "# Validation Features\n",
        "validation_features = np.expand_dims(val_features['melspectrogram'], axis=-1)\n",
        "print(validation_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdX5uTpE2DgX"
      },
      "outputs": [],
      "source": [
        "model = build_model(training_features)\n",
        "\n",
        "history = model.fit(\n",
        "    x=training_features,\n",
        "    y=train_y,\n",
        "    epochs=100,\n",
        "    validation_data=(\n",
        "        validation_features,\n",
        "        val_y,\n",
        "    ),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SZa9k4A2DgX"
      },
      "outputs": [],
      "source": [
        "visualize(history, 'mfcc_melspectrogram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJNaUUBM2DgX"
      },
      "outputs": [],
      "source": [
        "train_yhat = model.predict(training_features)\n",
        "train_yhat_result = np.argmax(train_yhat, axis=-1)\n",
        "train_results['mfcc_melspectrogram'] = model.evaluate(training_features, train_y)[-1]\n",
        "\n",
        "val_yhat = model.predict(validation_features)\n",
        "val_yhat_result = np.argmax(val_yhat, axis=-1)\n",
        "val_results['mfcc_melspectrogram'] = model.evaluate(validation_features, val_y)[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj4qRnzf2DgX"
      },
      "outputs": [],
      "source": [
        "val_scores['mfcc_melspectrogram'] = evaluate_model(val_y=val_y, val_yhat=val_yhat, val_yhat_result=val_yhat_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm5upEoh2DgX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC_qVONL2WbY"
      },
      "source": [
        "### With Mel Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4YDcx992WbZ"
      },
      "outputs": [],
      "source": [
        "# Train features\n",
        "target_size = 128\n",
        "\n",
        "training_features = np.expand_dims(train_features['melspectrogram'], axis=-1)\n",
        "print(training_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zaoChmk2WbZ"
      },
      "outputs": [],
      "source": [
        "# Validation Features\n",
        "target_size = 128\n",
        "validation_features = np.expand_dims(val_features['melspectrogram'], axis=-1)\n",
        "print(validation_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjxOVt8y2WbZ"
      },
      "outputs": [],
      "source": [
        "model = build_model(training_features)\n",
        "\n",
        "history = model.fit(\n",
        "    x=training_features,\n",
        "    y=train_y,\n",
        "    epochs=100,\n",
        "    validation_data=(\n",
        "        validation_features,\n",
        "        val_y,\n",
        "    ),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-fSuhO_2WbZ"
      },
      "outputs": [],
      "source": [
        "visualize(history, 'melspectrogram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ygiobez2WbZ"
      },
      "outputs": [],
      "source": [
        "train_yhat = model.predict(training_features)\n",
        "train_yhat_result = np.argmax(train_yhat, axis=-1)\n",
        "train_results['melspectrogram'] = model.evaluate(training_features, train_y)[-1]\n",
        "\n",
        "val_yhat = model.predict(validation_features)\n",
        "val_yhat_result = np.argmax(val_yhat, axis=-1)\n",
        "val_results['melspectrogram'] = model.evaluate(validation_features, val_y)[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8kkojL-2WbZ"
      },
      "outputs": [],
      "source": [
        "val_scores['melspectrogram'] = evaluate_model(val_y=val_y, val_yhat=val_yhat, val_yhat_result=val_yhat_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGiIO_K54vnQ"
      },
      "source": [
        "## Review all the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrEJwTc_4yHb"
      },
      "outputs": [],
      "source": [
        "train_results_df = pd.DataFrame(list(train_results.items()), columns=['Features', 'Train_Accuracy']).round(3)\n",
        "val_results_df = pd.DataFrame(list(val_results.items()), columns=['Features', 'Val_Accuracy']).round(3)\n",
        "\n",
        "result_df = train_results_df.merge(val_results_df, on='Features')\n",
        "result_df = result_df.sort_values('Features')\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OS9agBj4yvJ"
      },
      "outputs": [],
      "source": [
        "val_scores_df = pd.DataFrame([(key, value['f1'], value['auc']) for key, value in val_scores.items()],\n",
        "                             columns=['Features', 'F1_Score', 'AUC_Score']).round(3)\n",
        "\n",
        "val_scores_df = val_scores_df.sort_values('Features')\n",
        "print(val_scores_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}