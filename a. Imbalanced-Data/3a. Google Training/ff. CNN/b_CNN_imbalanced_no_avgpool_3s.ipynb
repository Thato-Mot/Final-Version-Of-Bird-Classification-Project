{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZbjVupctQds"
      },
      "source": [
        "# **Convolutional Neural Network**\n",
        "**Starting parameters**:\n",
        "\n",
        "- Number of epochs: 100\n",
        "- Learning rate: 0.0005\n",
        "- Layers: [64, 32, 32]\n",
        "- Dropout: 0.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIczGFG3tPW3",
        "outputId": "2afc8f5f-8f74-4aa7-f545-c76ceb4ecfd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fvbc5i78vXj1"
      },
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "# For preprocessing\n",
        "import tensorflow as tf\n",
        "\n",
        "# For modeling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Operational\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fXPOIwALvjaP"
      },
      "outputs": [],
      "source": [
        "pkl_path = '/content/drive/My Drive/Final-Year-Project/Dataset/Final-Version-of-Bird-Classification-Project/feature-extraction/NotAnnotated/Regular/NotAveragePooled/split_features_3s_all_2D.pkl'\n",
        "\n",
        "# Load the pickle file\n",
        "with open(pkl_path, 'rb') as file:\n",
        "    data = pickle.load(file)\n",
        "del file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PoAVhlX1xS-R"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/My Drive/Final-Year-Project/Final-Version-of-Bird-Classification-Project/Final-Version-of-Bird-Classification-Project/a. Imbalanced-Data/3. Training/Figures/CNN/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "enVU1ttOvoId"
      },
      "outputs": [],
      "source": [
        "train_data = data['train'].copy()\n",
        "val_data = data['val'].copy()\n",
        "del data\n",
        "\n",
        "train_labels = train_data['label'].copy()\n",
        "temp = train_data.copy()\n",
        "del temp['label']\n",
        "tr_features = temp\n",
        "\n",
        "val_labels = val_data['label'].copy()\n",
        "temp = val_data.copy()\n",
        "del temp['label']\n",
        "v_features = temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSALyZ_ov3Ar"
      },
      "source": [
        "## **Shuffling Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l56DzbZJvtSx"
      },
      "outputs": [],
      "source": [
        "def shuffle_data(input_label, input_features):\n",
        "  input_len = len(input_label)\n",
        "  np.random.seed(1826)\n",
        "  input_indices = np.random.permutation(input_len)\n",
        "  input_features = {key: np.array([input_features[key][i] for i in input_indices]) for key in input_features} # dictionary comprehension\n",
        "  input_label = np.array([input_label[i] for i in input_indices])\n",
        "\n",
        "  return input_label, input_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BADXTyNiv7lW"
      },
      "outputs": [],
      "source": [
        "train_y, train_features = shuffle_data(train_labels, tr_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mxUYFNO0v-Bg"
      },
      "outputs": [],
      "source": [
        "val_y, val_features = shuffle_data(val_labels, v_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6W0uaq-wCfJ"
      },
      "source": [
        "## **CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hxtoeAK_v-nu"
      },
      "outputs": [],
      "source": [
        "def build_model(audio_features,\n",
        "                learning_rate=0.00005):\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  # set audio features input layer\n",
        "  inputs = tf.keras.layers.Input(shape=(audio_features.shape[1],audio_features.shape[2],audio_features.shape[3]), name='Audio_Features')\n",
        "\n",
        "\n",
        "  features = tf.keras.layers.Conv2D(\n",
        "              filters=64,\n",
        "              kernel_size=(5,5),\n",
        "              strides=(1,1),\n",
        "              padding='same',\n",
        "              data_format='channels_last',\n",
        "              name='conv_1',\n",
        "              activation='relu',\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(0.15))(inputs)\n",
        "\n",
        "  features = tf.keras.layers.MaxPool2D(pool_size=(2,2), name='pool_1')(features)\n",
        "\n",
        "\n",
        "  features = tf.keras.layers.Conv2D(\n",
        "              filters=32,\n",
        "              kernel_size=(5,5),\n",
        "              strides=(1,1),\n",
        "              padding='same',\n",
        "              name='conv_2',\n",
        "              activation='relu',\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(0.15))(features)\n",
        "\n",
        "  # features = tf.keras.layers.MaxPool2D(pool_size=(2,2), name='pool_2')(features)\n",
        "\n",
        "\n",
        "  # features = tf.keras.layers.Conv2D(\n",
        "  #             filters=32,\n",
        "  #             kernel_size=(5,5),\n",
        "  #             strides=(1,1),\n",
        "  #             padding='same',\n",
        "  #             name='conv_3',\n",
        "  #             activation='relu',\n",
        "  #             kernel_regularizer=tf.keras.regularizers.l2(0.15))(features)\n",
        "\n",
        "  # features = tf.keras.layers.BatchNormalization()(features)\n",
        "  features = tf.keras.layers.MaxPool2D(pool_size=(4,4), name='pool_3')(features)\n",
        "\n",
        "  # add a fully connected layer (need to flatten the output of the previous layers first)\n",
        "  features = tf.keras.layers.Flatten()(features)\n",
        "\n",
        "  features = tf.keras.layers.Dense(\n",
        "      units=256,\n",
        "      name='fc_1',\n",
        "      activation='relu')(features)\n",
        "\n",
        "  # add dropout layer\n",
        "  features = tf.keras.layers.Dropout(rate=0.5)(features)\n",
        "\n",
        "  # add the last fully connected layer\n",
        "  # this last layer sets the activation function to \"None\" in order to output the logits\n",
        "  # note that passing activation = \"softmax\" will return class memembership probabilities\n",
        "  outputs = tf.keras.layers.Dense(\n",
        "      units=20,\n",
        "      name='fc_2',\n",
        "      activation='softmax')(features)\n",
        "\n",
        "  # build model and print summary\n",
        "  model = tf.keras.Model(inputs=[inputs],\n",
        "                          outputs=outputs,\n",
        "                          name='Birds')\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  # compile model\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'],\n",
        "              weighted_metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_q4T8A9kwn_w"
      },
      "outputs": [],
      "source": [
        "def visualize(model_history, name):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "    # Visualize the loss\n",
        "    axes[0].plot(model_history.history['loss'], color='red', label='Training Loss')\n",
        "    axes[0].plot(model_history.history['val_loss'], color='blue', label='Validation Loss')\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Loss', fontsize=12)\n",
        "    axes[0].set_title('Loss Progression', fontsize=14)\n",
        "    axes[0].grid(True)\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Visualize the accuracy\n",
        "    axes[1].plot(model_history.history['accuracy'], color='green', label='Training Accuracy')\n",
        "    axes[1].plot(model_history.history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "    axes[1].set_title('Accuracy Progression', fontsize=14)\n",
        "    axes[1].grid(True)\n",
        "    axes[1].legend()\n",
        "\n",
        "    plt.savefig(f'{path+name}_3s_model_training_history_2D_annotated_2.pdf')\n",
        "\n",
        "    # Fine-tune layout and display the plots\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FQ6ySd5FzwJo"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(val_y, val_yhat, val_yhat_result, num_classes=20):\n",
        "\n",
        "    print('Validation classification Report \\n')\n",
        "    print(classification_report(val_y, val_yhat_result))\n",
        "\n",
        "    # Calculate AUC for multiclass classification using 'ovr' and 'weighted' average\n",
        "    auc_score = roc_auc_score(val_y, val_yhat, multi_class='ovr', average='weighted')\n",
        "    print(f'AUC Score: {auc_score}')\n",
        "\n",
        "    # Calculate F1-score with 'weighted' average for imbalanced dataset\n",
        "    f1 = f1_score(val_y, val_yhat_result, average='weighted')\n",
        "    print(f'F1 Score (Weighted): {f1}')\n",
        "\n",
        "    val_score = {'f1': f1, 'auc': auc_score}\n",
        "\n",
        "    return val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "47vW1YbuYIIl"
      },
      "outputs": [],
      "source": [
        "def tile_and_crop(feature, target_size):\n",
        "    tiled = np.tile(feature, (1, target_size // feature.shape[1] + 1, 1))\n",
        "    return tiled[:, :target_size, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DObv-Sqeyb0G"
      },
      "outputs": [],
      "source": [
        "train_results = {}\n",
        "val_results = {}\n",
        "\n",
        "val_scores = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-hlTtXpy360"
      },
      "source": [
        "### With All Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nsjck8K5YPSi",
        "outputId": "a5c543b0-8d94-43eb-9c83-13677070bbbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13725, 128, 259, 4)\n"
          ]
        }
      ],
      "source": [
        "# Train features\n",
        "target_size = 128\n",
        "mfcc_tiled = tile_and_crop(train_features['mfcc'], target_size)\n",
        "cqt_tiled = tile_and_crop(train_features['cqt'], target_size)\n",
        "chroma_tiled = tile_and_crop(train_features['chroma'], target_size)\n",
        "\n",
        "training_features = np.stack((train_features['melspectrogram'], mfcc_tiled, chroma_tiled, cqt_tiled), axis=-1)\n",
        "print(training_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkVMNm9IYWA8",
        "outputId": "15e305f1-1e44-42f6-d4cf-e1c3f687f315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4231, 128, 259, 4)\n"
          ]
        }
      ],
      "source": [
        "# Validation Features\n",
        "target_size = 128\n",
        "mfcc_tiled = tile_and_crop(val_features['mfcc'], target_size)\n",
        "cqt_tiled = tile_and_crop(val_features['cqt'], target_size)\n",
        "chroma_tiled = tile_and_crop(val_features['chroma'], target_size)\n",
        "\n",
        "validation_features = np.stack((val_features['melspectrogram'], mfcc_tiled, chroma_tiled, cqt_tiled), axis=-1)\n",
        "print(validation_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QOVKae0_zB-q",
        "outputId": "0dc59e62-6187-4129-994c-8351358e4851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Birds\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Audio_Features (InputLayer  [(None, 128, 259, 4)]     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_1 (Conv2D)             (None, 128, 259, 64)      6464      \n",
            "                                                                 \n",
            " pool_1 (MaxPooling2D)       (None, 64, 129, 64)       0         \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 64, 129, 32)       51232     \n",
            "                                                                 \n",
            " pool_3 (MaxPooling2D)       (None, 16, 32, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " fc_1 (Dense)                (None, 256)               4194560   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " fc_2 (Dense)                (None, 20)                5140      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4257396 (16.24 MB)\n",
            "Trainable params: 4257396 (16.24 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 279s 648ms/step - loss: 8.7670 - accuracy: 0.1491 - weighted_accuracy: 0.1491 - val_loss: 7.0235 - val_accuracy: 0.1678 - val_weighted_accuracy: 0.1678\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 273s 636ms/step - loss: 5.9625 - accuracy: 0.2343 - weighted_accuracy: 0.2343 - val_loss: 5.4140 - val_accuracy: 0.2165 - val_weighted_accuracy: 0.2165\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 271s 632ms/step - loss: 4.6478 - accuracy: 0.3527 - weighted_accuracy: 0.3527 - val_loss: 4.4909 - val_accuracy: 0.3373 - val_weighted_accuracy: 0.3373\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 270s 630ms/step - loss: 3.8609 - accuracy: 0.4405 - weighted_accuracy: 0.4405 - val_loss: 3.9946 - val_accuracy: 0.3158 - val_weighted_accuracy: 0.3158\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 271s 633ms/step - loss: 3.3103 - accuracy: 0.5175 - weighted_accuracy: 0.5175 - val_loss: 3.7397 - val_accuracy: 0.3200 - val_weighted_accuracy: 0.3200\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 270s 629ms/step - loss: 2.9166 - accuracy: 0.5611 - weighted_accuracy: 0.5611 - val_loss: 3.4360 - val_accuracy: 0.3536 - val_weighted_accuracy: 0.3536\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 269s 628ms/step - loss: 2.6021 - accuracy: 0.6001 - weighted_accuracy: 0.6001 - val_loss: 3.3120 - val_accuracy: 0.3455 - val_weighted_accuracy: 0.3455\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 270s 628ms/step - loss: 2.3717 - accuracy: 0.6249 - weighted_accuracy: 0.6249 - val_loss: 3.1452 - val_accuracy: 0.3536 - val_weighted_accuracy: 0.3536\n",
            "Epoch 9/100\n",
            "  6/429 [..............................] - ETA: 4:10 - loss: 2.3410 - accuracy: 0.6250 - weighted_accuracy: 0.6250"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-841c33188590>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = build_model(training_features)\n",
        "\n",
        "history = model.fit(\n",
        "    x=training_features,\n",
        "    y=train_y,\n",
        "    epochs=100,\n",
        "    validation_data=(\n",
        "        validation_features,\n",
        "        val_y,\n",
        "    ),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyGOcWZGzLkg"
      },
      "outputs": [],
      "source": [
        "visualize(history, 'all_features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH1TokYZzXAO"
      },
      "outputs": [],
      "source": [
        "train_yhat = model.predict(training_features)\n",
        "train_yhat_result = np.argmax(train_yhat, axis=-1)\n",
        "train_results['all_features'] = model.evaluate(training_features, train_y)[-1]\n",
        "\n",
        "val_yhat = model.predict(validation_features)\n",
        "val_yhat_result = np.argmax(val_yhat, axis=-1)\n",
        "val_results['all_features'] = model.evaluate(validation_features, val_y)[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiS_Cf1wzdaX"
      },
      "outputs": [],
      "source": [
        "val_scores['all_features'] = evaluate_model(val_y=val_y, val_yhat=val_yhat, val_yhat_result=val_yhat_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdDIuhtw019E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt9hAfOd1pnO"
      },
      "source": [
        "### Mel Spectrogram and Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8KM5tfw1pnO"
      },
      "outputs": [],
      "source": [
        "# Train features\n",
        "target_size = 128\n",
        "chroma_tiled = tile_and_crop(train_features['chroma'], target_size)\n",
        "\n",
        "training_features = np.stack((train_features['melspectrogram'],  chroma_tiled), axis=-1)\n",
        "print(training_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMJdKrh81pnP"
      },
      "outputs": [],
      "source": [
        "# Validation Features\n",
        "target_size = 128\n",
        "chroma_tiled = tile_and_crop(val_features['chroma'], target_size)\n",
        "\n",
        "validation_features = np.stack((val_features['melspectrogram'],  chroma_tiled), axis=-1)\n",
        "print(validation_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENX_W2qL1pnP"
      },
      "outputs": [],
      "source": [
        "model = build_model(training_features)\n",
        "\n",
        "history = model.fit(\n",
        "    x=training_features,\n",
        "    y=train_y,\n",
        "    epochs=100,\n",
        "    validation_data=(\n",
        "        validation_features,\n",
        "        val_y,\n",
        "    ),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41Spn4T51pnP"
      },
      "outputs": [],
      "source": [
        "visualize(history, 'melspectrogram_chroma')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laEEYNuq1pnP"
      },
      "outputs": [],
      "source": [
        "train_yhat = model.predict(training_features)\n",
        "train_yhat_result = np.argmax(train_yhat, axis=-1)\n",
        "train_results['melspectrogram_chroma'] = model.evaluate(training_features, train_y)[-1]\n",
        "\n",
        "val_yhat = model.predict(validation_features)\n",
        "val_yhat_result = np.argmax(val_yhat, axis=-1)\n",
        "val_results['melspectrogram_chroma'] = model.evaluate(validation_features, val_y)[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQsqbxrT1pnP"
      },
      "outputs": [],
      "source": [
        "val_scores['melspectrogram_chroma'] = evaluate_model(val_y=val_y, val_yhat=val_yhat, val_yhat_result=val_yhat_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W06qAtR1pnP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4lftzxy1Qax"
      },
      "source": [
        "### With Mel Spectrogram, MFCCs and Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxXJ9f2d1Qax"
      },
      "outputs": [],
      "source": [
        "# Train features\n",
        "target_size = 128\n",
        "mfcc_tiled = tile_and_crop(train_features['mfcc'], target_size)\n",
        "chroma_tiled = tile_and_crop(train_features['chroma'], target_size)\n",
        "\n",
        "training_features = np.stack((train_features['melspectrogram'], mfcc_tiled, chroma_tiled), axis=-1)\n",
        "print(training_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7a8E2je1Qax"
      },
      "outputs": [],
      "source": [
        "# Validation Features\n",
        "target_size = 128\n",
        "mfcc_tiled = tile_and_crop(val_features['mfcc'], target_size)\n",
        "chroma_tiled = tile_and_crop(val_features['chroma'], target_size)\n",
        "\n",
        "validation_features = np.stack((val_features['melspectrogram'], mfcc_tiled, chroma_tiled), axis=-1)\n",
        "print(validation_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn_2p1QN1Qax"
      },
      "outputs": [],
      "source": [
        "model = build_model(training_features)\n",
        "\n",
        "history = model.fit(\n",
        "    x=training_features,\n",
        "    y=train_y,\n",
        "    epochs=100,\n",
        "    validation_data=(\n",
        "        validation_features,\n",
        "        val_y,\n",
        "    ),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmfoULEj1Qax"
      },
      "outputs": [],
      "source": [
        "visualize(history, 'melspectrogram_chroma_mfcc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usP8vZzt1Qax"
      },
      "outputs": [],
      "source": [
        "train_yhat = model.predict(training_features)\n",
        "train_yhat_result = np.argmax(train_yhat, axis=-1)\n",
        "train_results['melspectrogram_chroma_mfcc'] = model.evaluate(training_features, train_y)[-1]\n",
        "\n",
        "val_yhat = model.predict(validation_features)\n",
        "val_yhat_result = np.argmax(val_yhat, axis=-1)\n",
        "val_results['melspectrogram_chroma_mfcc'] = model.evaluate(validation_features, val_y)[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2V-Ga_t1Qay"
      },
      "outputs": [],
      "source": [
        "val_scores['melspectrogram_chroma_mfcc'] = evaluate_model(val_y=val_y, val_yhat=val_yhat, val_yhat_result=val_yhat_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PziaOMkc2DgW"
      },
      "source": [
        "### With Mel Spectrogram and MFCCs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB2jtaj52DgW"
      },
      "outputs": [],
      "source": [
        "# Train features\n",
        "target_size = 128\n",
        "mfcc_tiled = tile_and_crop(train_features['mfcc'], target_size)\n",
        "\n",
        "training_features = np.stack((train_features['melspectrogram'], mfcc_tiled), axis=-1)\n",
        "print(training_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNWboY3f2DgW"
      },
      "outputs": [],
      "source": [
        "# Validation Features\n",
        "target_size = 128\n",
        "mfcc_tiled = tile_and_crop(val_features['mfcc'], target_size)\n",
        "\n",
        "validation_features = np.stack((val_features['melspectrogram'], mfcc_tiled), axis=-1)\n",
        "print(validation_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdX5uTpE2DgX"
      },
      "outputs": [],
      "source": [
        "model = build_model(training_features)\n",
        "\n",
        "history = model.fit(\n",
        "    x=training_features,\n",
        "    y=train_y,\n",
        "    epochs=100,\n",
        "    validation_data=(\n",
        "        validation_features,\n",
        "        val_y,\n",
        "    ),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SZa9k4A2DgX"
      },
      "outputs": [],
      "source": [
        "visualize(history, 'mfcc_melspectrogram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJNaUUBM2DgX"
      },
      "outputs": [],
      "source": [
        "train_yhat = model.predict(training_features)\n",
        "train_yhat_result = np.argmax(train_yhat, axis=-1)\n",
        "train_results['mfcc_melspectrogram'] = model.evaluate(training_features, train_y)[-1]\n",
        "\n",
        "val_yhat = model.predict(validation_features)\n",
        "val_yhat_result = np.argmax(val_yhat, axis=-1)\n",
        "val_results['mfcc_melspectrogram'] = model.evaluate(validation_features, val_y)[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj4qRnzf2DgX"
      },
      "outputs": [],
      "source": [
        "val_scores['mfcc_melspectrogram'] = evaluate_model(val_y=val_y, val_yhat=val_yhat, val_yhat_result=val_yhat_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm5upEoh2DgX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC_qVONL2WbY"
      },
      "source": [
        "### With Mel Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4YDcx992WbZ"
      },
      "outputs": [],
      "source": [
        "# Train features\n",
        "target_size = 128\n",
        "\n",
        "training_features = np.expand_dims(train_features['melspectrogram'], axis=-1)\n",
        "print(training_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zaoChmk2WbZ"
      },
      "outputs": [],
      "source": [
        "# Validation Features\n",
        "target_size = 128\n",
        "validation_features = np.expand_dims(val_features['melspectrogram'], axis=-1)\n",
        "print(validation_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjxOVt8y2WbZ"
      },
      "outputs": [],
      "source": [
        "model = build_model(training_features)\n",
        "\n",
        "history = model.fit(\n",
        "    x=training_features,\n",
        "    y=train_y,\n",
        "    epochs=100,\n",
        "    validation_data=(\n",
        "        validation_features,\n",
        "        val_y,\n",
        "    ),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-fSuhO_2WbZ"
      },
      "outputs": [],
      "source": [
        "visualize(history, 'melspectrogram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ygiobez2WbZ"
      },
      "outputs": [],
      "source": [
        "train_yhat = model.predict(training_features)\n",
        "train_yhat_result = np.argmax(train_yhat, axis=-1)\n",
        "train_results['melspectrogram'] = model.evaluate(training_features, train_y)[-1]\n",
        "\n",
        "val_yhat = model.predict(validation_features)\n",
        "val_yhat_result = np.argmax(val_yhat, axis=-1)\n",
        "val_results['melspectrogram'] = model.evaluate(validation_features, val_y)[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8kkojL-2WbZ"
      },
      "outputs": [],
      "source": [
        "val_scores['melspectrogram'] = evaluate_model(val_y=val_y, val_yhat=val_yhat, val_yhat_result=val_yhat_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGiIO_K54vnQ"
      },
      "source": [
        "## Review all the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrEJwTc_4yHb"
      },
      "outputs": [],
      "source": [
        "train_results_df = pd.DataFrame(list(train_results.items()), columns=['Features', 'Train_Accuracy']).round(3)\n",
        "val_results_df = pd.DataFrame(list(val_results.items()), columns=['Features', 'Val_Accuracy']).round(3)\n",
        "\n",
        "result_df = train_results_df.merge(val_results_df, on='Features')\n",
        "result_df = result_df.sort_values('Features')\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OS9agBj4yvJ"
      },
      "outputs": [],
      "source": [
        "val_scores_df = pd.DataFrame([(key, value['f1'], value['auc']) for key, value in val_scores.items()],\n",
        "                             columns=['Features', 'F1_Score', 'AUC_Score']).round(3)\n",
        "\n",
        "val_scores_df = val_scores_df.sort_values('Features')\n",
        "print(val_scores_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}