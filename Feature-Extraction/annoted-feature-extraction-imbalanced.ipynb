{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Extraction Methods: Imbalanced Data With Annotations**\n",
    "\n",
    "- *Key Features*: [MFCCs, Mel-Spectrograms, Chroma Frequencies, RMS Power]\n",
    "- *Key Manipulations*: [Varying Window Sizes, Normalization, Average Pooling (Compression), Filtering]\n",
    "- *Process Assistence*: [Converting them to numpy arrays now, easy label access across features]\n",
    "- *Conversion*: [To numpy arrays and pkl files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Libraries for audio\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Training and Testing Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for normalization & avgpooling features\n",
    "import tensorflow as tf\n",
    "# for preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Operational\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import scipy.ndimage\n",
    "import pygame\n",
    "import time\n",
    "from scipy.signal import butter, filtfilt\n",
    "import random\n",
    "import IPython.display as ipd\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabels to be reused\n",
    "path = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/audio_files' \n",
    "npy_path = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/train_audio_npy/' \n",
    "train_csv = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/train-not-annotated.csv' \n",
    "annotated_train_csv = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/trainval-split/trainval-annotated.csv'\n",
    "not_annotated_splt = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/trainval-split/trainval.csv'\n",
    "sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_data = pd.read_csv(annotated_train_csv)\n",
    "train_data = trainval_data[trainval_data['set'] == 'tr']\n",
    "val_data = trainval_data[trainval_data['set'] == 'val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating a class to do the extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extraction:\n",
    "  def __init__(self, train_df, val_df, window_size, overlap=0.5, npy_path=npy_path, sr=sr, n_mels=60, n_mfcc=20, n_chroma=12, features=['mfcc'], normalize=True, avgpool=False):\n",
    "    \"\"\"\n",
    "    Instantiate the Extraction class to extract features.\n",
    "\n",
    "    Parameters:\n",
    "      sr (int): Sample rate of the audio files.\n",
    "      n_mfccs (int): Number of MFCCs to extract.\n",
    "      n_mels (int): Number of Mel bands to extract.\n",
    "      n_chroma (int): Number of chroma bins to use.\n",
    "      features (list): List of features to extract.\n",
    "        accepted features: 'mfcc', 'chroma', 'rms', 'melspectrogram'.\n",
    "      normalize (bool): Whether to normalize the features.\n",
    "      maxpool (bool): Whether to maxpool the features.\n",
    "    \"\"\"\n",
    "    \n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.npy_path = npy_path\n",
    "    self.window_size = window_size\n",
    "    self.overlap = overlap\n",
    "    self.sr = sr\n",
    "    self.n_mels = n_mels\n",
    "    self.n_mfcc = n_mfcc\n",
    "    self.n_chroma = n_chroma\n",
    "\n",
    "     # confirm features have been specified\n",
    "    assert len(features) != 0, \"Must Specify At Least One Feature In The Form Of A List.\"\n",
    "    self.features = features\n",
    "\n",
    "    self.accepted_feature = ['mfcc', 'chroma', 'rms', 'melspectrogram']\n",
    "    for feature in self.features:\n",
    "      assert feature in self.accepted_feature, f\"{feature} is not an accepted feature, only 'mfcc', 'chroma', 'rms', 'melspectrogram' are accepted features.\"\n",
    "\n",
    "    self.normalize = normalize\n",
    "    self.avgpool = avgpool\n",
    "\n",
    "    print(f\"Train DataFrame shape: {train_df.shape}\")\n",
    "    print(f\"Validation DataFrame shape: {val_df.shape}\")\n",
    "\n",
    "    # extract train and val labels and features\n",
    "    self.train_y, self.train_features = self.feature_extraction(self.train_df, window_size=self.window_size)\n",
    "    self.val_y, self.val_features = self.feature_extraction(self.val_df, window_size=self.window_size)\n",
    "\n",
    "    # process the features by average pooling\n",
    "    self.train_features, self.val_features = self.process_features(self.train_features, self.val_features)\n",
    "\n",
    "    \n",
    "  \n",
    "\n",
    "  def normalize_audio(self, audio):\n",
    "    return (audio - np.min(audio)) / (np.max(audio) - np.min(audio))\n",
    "  \n",
    "  def bandpass_filter(self, audio, lowcut=800, highcut=8000, order=4):\n",
    "    nyquist = 0.5 * self.sr  # Nyquist frequency\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    filtered_audio = filtfilt(b, a, audio)\n",
    "    return filtered_audio\n",
    "  \n",
    "  def generate_pink_noise(self, num_samples):\n",
    "    white_noise = np.random.randn(num_samples)\n",
    "    \n",
    "    # Apply a filter to convert white noise into pink noise (1/f noise)\n",
    "    X = np.fft.rfft(white_noise)\n",
    "    S = np.arange(1, len(X) + 1)  # Frequency scaling\n",
    "    pink_noise = np.fft.irfft(X / S)\n",
    "    \n",
    "    return self.normalize_audio(pink_noise)\n",
    "  \n",
    "  def pad_with_noise(self, audio_data, window_length):\n",
    "    current_length = librosa.get_duration(y=audio_data, sr=self.sr)\n",
    "    if current_length >= window_length:\n",
    "        return audio_data\n",
    "    \n",
    "    target_length_samples = int(window_length * sr) + 1\n",
    "    current_length_samples = len(audio_data)\n",
    "    padding_length_samples = target_length_samples - current_length_samples\n",
    "    \n",
    "    # Generate pink noise to pad with\n",
    "    pink_noise = self.generate_pink_noise(padding_length_samples)\n",
    "    padded_audio = np.concatenate([audio_data, pink_noise])\n",
    "    \n",
    "    return padded_audio\n",
    "  \n",
    "  def avg_pooling_keras(self, feature):\n",
    "    # Clear the previous Keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Define the input shape based on features\n",
    "    input_shape = feature.shape[1:]  # (n_mels, time_steps)\n",
    "\n",
    "    # Create the Keras model for average pooling\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    pooled = tf.keras.layers.GlobalAveragePooling1D()(inputs)\n",
    "    pooling_model = tf.keras.models.Model(inputs=inputs, outputs=pooled)\n",
    "\n",
    "    # Perform pooling using the model\n",
    "    pooled_features = pooling_model.predict(feature)\n",
    "\n",
    "    return pooled_features\n",
    "\n",
    "#-------------------------Feature Extraction---------------------------------------\n",
    "  def extract_mfcc(self, window):\n",
    "    mfcc = librosa.feature.mfcc(y=window, sr=self.sr, n_mfcc=self.n_mfcc)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(mfcc)\n",
    "    else:\n",
    "      return mfcc\n",
    "\n",
    "\n",
    "  def extract_chroma(self, window):\n",
    "    chroma = librosa.feature.chroma_stft(y=window, sr=self.sr, n_chroma=self.n_chroma)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(chroma)\n",
    "    else:\n",
    "      return chroma\n",
    "   \n",
    "\n",
    "  def extract_rms(self, window):\n",
    "    return librosa.feature.rms(y=window)\n",
    "\n",
    "  def extract_melspectrogram(self, window):\n",
    "    mel = librosa.feature.melspectrogram(y=window, sr=self.sr, n_mels=self.n_mels)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(mel)\n",
    "    else:\n",
    "      return mel\n",
    "    \n",
    "  def avgpooling(self, train_X, val_X, n_time, n_features):\n",
    "    \"\"\"\n",
    "    Average pooling the train and val features.\n",
    "\n",
    "    Parameters:\n",
    "      train_X (npy): Training feature array of shape (batch_size, n_features, n_time)\n",
    "      val_X (npy): Validation feature array of shape (batch_size, n_features, n_time)\n",
    "      n_time (int): Time axis\n",
    "      n_features (int): Feature axis\n",
    "\n",
    "    Returns:\n",
    "      train_X (npy): Avgpooled training feature array of shape (batch_size, n_features)\n",
    "      val_X (npy): Avgpooled validation feature array of shape (batch_size, n_features)\n",
    "    \"\"\"\n",
    "    # Clear the Keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Create the Keras input layer with shape (n_features, n_time)\n",
    "    input_layer = tf.keras.layers.Input(shape=(n_features, n_time))\n",
    "    \n",
    "    # Apply average pooling over the time axis (axis=-1) to reduce n_time\n",
    "    avg_pool = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1))(input_layer)\n",
    "    \n",
    "    # Build the model\n",
    "    pooling_model = tf.keras.models.Model(inputs=input_layer, outputs=avg_pool)\n",
    "\n",
    "    # Use the model to apply average pooling on the training and validation features\n",
    "    train_X = pooling_model.predict(train_X)\n",
    "    val_X = pooling_model.predict(val_X)\n",
    "\n",
    "    return train_X, val_X\n",
    "\n",
    "    \n",
    "  def process_features(self, train_features_dict, val_features_dict):\n",
    "    for each in train_features_dict.keys():\n",
    "      \n",
    "      if each == 'mfcc':\n",
    "        n_features=self.n_mfcc\n",
    "      elif each == 'chroma':\n",
    "        n_features=self.n_chroma\n",
    "      elif each == 'rms':\n",
    "        n_features=1\n",
    "      elif each == 'melspectrogram':\n",
    "        n_features=self.n_mels\n",
    "      \n",
    "      train_feature = train_features_dict[each]\n",
    "      val_feature = val_features_dict[each]\n",
    "\n",
    "      if self.avgpool:\n",
    "        train_features_dict[each], val_features_dict[each] = self.avgpooling(train_feature, val_feature, n_time=train_feature.shape[2], n_features=n_features)\n",
    "      else:\n",
    "        train_features_dict[each], val_features_dict[each] = train_features_dict[each], val_features_dict[each]\n",
    "    \n",
    "    return train_features_dict, val_features_dict\n",
    "      \n",
    "\n",
    "  def feature_extraction(self, dataframe, window_size, filter=True):\n",
    "    y = [] # To hold the labels\n",
    "    features_dict = {item: [] for item in self.features} # Create a key for each feature listed\n",
    "    print(f\"Number of rows in dataframe: {len(dataframe)}\")\n",
    "    for _, row in tqdm(dataframe.iterrows(), desc=\"Processing data\", total=len(dataframe)):\n",
    "          label = row['species']\n",
    "          file_path = os.path.join(self.npy_path, row['filename_npy'])\n",
    "          start = row['start']\n",
    "          end = row['end']\n",
    "\n",
    "          # print(f\"Processing file: {file_path}\")\n",
    "\n",
    "          try:\n",
    "            \n",
    "              audio = np.load(file_path)\n",
    "          except FileNotFoundError:\n",
    "              print(f\"File not found: {file_path}\")\n",
    "              continue\n",
    "\n",
    "\n",
    "          start = int(start * sr)\n",
    "          end = int(end * sr)\n",
    "          sample = audio[start:end]\n",
    "\n",
    "          sample = self.normalize_audio(sample)\n",
    "          sample = self.pad_with_noise(sample, window_length=window_size)\n",
    "\n",
    "          if filter:\n",
    "                  sample = self.bandpass_filter(sample)\n",
    "\n",
    "          window_samples = int(window_size * self.sr)\n",
    "          hop_samples = int(window_samples * (1 - self.overlap))  # For overlapping\n",
    "\n",
    "          # Break the audio into windows with the specified overlap\n",
    "          audio_windows = librosa.util.frame(sample, frame_length=window_samples, hop_length=hop_samples).T\n",
    "          \n",
    "          \n",
    "          # display(label)\n",
    "          \n",
    "          for _, window in enumerate(audio_windows):\n",
    "              \n",
    "              y.append(label)\n",
    "\n",
    "              if len(window) < window_samples:\n",
    "                  window = self.pad_with_noise(window, window_length=window_size)\n",
    "              \n",
    "              # Feature Extraction FR --------------------------------------------------------------------\n",
    "              # dynatically call the extract_x function to extract the listed features\n",
    "              for feature in self.features:\n",
    "                extract = f\"extract_{feature}\"\n",
    "                if hasattr(self, extract) and callable(func := getattr(self, extract)):\n",
    "                  features_dict[feature].append(func(window))\n",
    "\n",
    "          # cast lists to np arrays\n",
    "    for each in features_dict.keys():\n",
    "              features_dict[each] = np.array(features_dict[each])\n",
    "\n",
    "    y = np.array(y)\n",
    "\n",
    "          # If not using average pooling, return resized features\n",
    "    return y, features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No Average Pooling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Window Size = 1s**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train = train_data[6:15]\n",
    "test_val = val_data[6:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>species</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>filename_npy</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Alcedo atthis</td>\n",
       "      <td>XC503772.mp3</td>\n",
       "      <td>9.195102</td>\n",
       "      <td>Alcedo atthis/XC503772.npy</td>\n",
       "      <td>6.820139</td>\n",
       "      <td>7.072361</td>\n",
       "      <td>call</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Alcedo atthis</td>\n",
       "      <td>XC503772.mp3</td>\n",
       "      <td>9.195102</td>\n",
       "      <td>Alcedo atthis/XC503772.npy</td>\n",
       "      <td>7.634562</td>\n",
       "      <td>7.897283</td>\n",
       "      <td>call</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Himantopus himantopus</td>\n",
       "      <td>XC154289.mp3</td>\n",
       "      <td>30.484898</td>\n",
       "      <td>Himantopus himantopus/XC154289.npy</td>\n",
       "      <td>1.306496</td>\n",
       "      <td>12.019761</td>\n",
       "      <td>call</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Himantopus himantopus</td>\n",
       "      <td>XC154289.mp3</td>\n",
       "      <td>30.484898</td>\n",
       "      <td>Himantopus himantopus/XC154289.npy</td>\n",
       "      <td>17.419942</td>\n",
       "      <td>25.433116</td>\n",
       "      <td>call</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Himantopus himantopus</td>\n",
       "      <td>XC154289.mp3</td>\n",
       "      <td>30.484898</td>\n",
       "      <td>Himantopus himantopus/XC154289.npy</td>\n",
       "      <td>25.973133</td>\n",
       "      <td>28.516444</td>\n",
       "      <td>call</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Motacilla flava</td>\n",
       "      <td>XC281358.mp3</td>\n",
       "      <td>30.746122</td>\n",
       "      <td>Motacilla flava/XC281358.npy</td>\n",
       "      <td>7.677746</td>\n",
       "      <td>8.362939</td>\n",
       "      <td>song</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Motacilla flava</td>\n",
       "      <td>XC281358.mp3</td>\n",
       "      <td>30.746122</td>\n",
       "      <td>Motacilla flava/XC281358.npy</td>\n",
       "      <td>14.231062</td>\n",
       "      <td>14.810836</td>\n",
       "      <td>song</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Motacilla flava</td>\n",
       "      <td>XC281358.mp3</td>\n",
       "      <td>30.746122</td>\n",
       "      <td>Motacilla flava/XC281358.npy</td>\n",
       "      <td>19.317350</td>\n",
       "      <td>19.800501</td>\n",
       "      <td>song</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Motacilla flava</td>\n",
       "      <td>XC281358.mp3</td>\n",
       "      <td>30.746122</td>\n",
       "      <td>Motacilla flava/XC281358.npy</td>\n",
       "      <td>23.885345</td>\n",
       "      <td>24.667159</td>\n",
       "      <td>song</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                species    audio_name   duration  \\\n",
       "6            6          Alcedo atthis  XC503772.mp3   9.195102   \n",
       "7            7          Alcedo atthis  XC503772.mp3   9.195102   \n",
       "8            8  Himantopus himantopus  XC154289.mp3  30.484898   \n",
       "9            9  Himantopus himantopus  XC154289.mp3  30.484898   \n",
       "10          10  Himantopus himantopus  XC154289.mp3  30.484898   \n",
       "11          11        Motacilla flava  XC281358.mp3  30.746122   \n",
       "12          12        Motacilla flava  XC281358.mp3  30.746122   \n",
       "13          13        Motacilla flava  XC281358.mp3  30.746122   \n",
       "14          14        Motacilla flava  XC281358.mp3  30.746122   \n",
       "\n",
       "                          filename_npy      start        end label set  \n",
       "6           Alcedo atthis/XC503772.npy   6.820139   7.072361  call  tr  \n",
       "7           Alcedo atthis/XC503772.npy   7.634562   7.897283  call  tr  \n",
       "8   Himantopus himantopus/XC154289.npy   1.306496  12.019761  call  tr  \n",
       "9   Himantopus himantopus/XC154289.npy  17.419942  25.433116  call  tr  \n",
       "10  Himantopus himantopus/XC154289.npy  25.973133  28.516444  call  tr  \n",
       "11        Motacilla flava/XC281358.npy   7.677746   8.362939  song  tr  \n",
       "12        Motacilla flava/XC281358.npy  14.231062  14.810836  song  tr  \n",
       "13        Motacilla flava/XC281358.npy  19.317350  19.800501  song  tr  \n",
       "14        Motacilla flava/XC281358.npy  23.885345  24.667159  song  tr  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>species</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>filename_npy</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>Circus aeruginosus</td>\n",
       "      <td>XC269745.mp3</td>\n",
       "      <td>47.777959</td>\n",
       "      <td>Circus aeruginosus/XC269745.npy</td>\n",
       "      <td>4.038441</td>\n",
       "      <td>5.702931</td>\n",
       "      <td>call</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>Circus aeruginosus</td>\n",
       "      <td>XC269745.mp3</td>\n",
       "      <td>47.777959</td>\n",
       "      <td>Circus aeruginosus/XC269745.npy</td>\n",
       "      <td>17.831900</td>\n",
       "      <td>19.714692</td>\n",
       "      <td>call</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>Circus aeruginosus</td>\n",
       "      <td>XC269745.mp3</td>\n",
       "      <td>47.777959</td>\n",
       "      <td>Circus aeruginosus/XC269745.npy</td>\n",
       "      <td>29.005830</td>\n",
       "      <td>29.619776</td>\n",
       "      <td>call</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>Circus aeruginosus</td>\n",
       "      <td>XC269745.mp3</td>\n",
       "      <td>47.777959</td>\n",
       "      <td>Circus aeruginosus/XC269745.npy</td>\n",
       "      <td>30.274664</td>\n",
       "      <td>30.943191</td>\n",
       "      <td>call</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>Circus aeruginosus</td>\n",
       "      <td>XC269745.mp3</td>\n",
       "      <td>47.777959</td>\n",
       "      <td>Circus aeruginosus/XC269745.npy</td>\n",
       "      <td>34.463183</td>\n",
       "      <td>34.995292</td>\n",
       "      <td>call</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>Circus aeruginosus</td>\n",
       "      <td>XC269745.mp3</td>\n",
       "      <td>47.777959</td>\n",
       "      <td>Circus aeruginosus/XC269745.npy</td>\n",
       "      <td>36.605194</td>\n",
       "      <td>38.801770</td>\n",
       "      <td>call</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>Dendrocopos minor</td>\n",
       "      <td>XC329937.mp3</td>\n",
       "      <td>60.065578</td>\n",
       "      <td>Dendrocopos minor/XC329937.npy</td>\n",
       "      <td>1.683749</td>\n",
       "      <td>2.903613</td>\n",
       "      <td>drumming</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>Dendrocopos minor</td>\n",
       "      <td>XC329937.mp3</td>\n",
       "      <td>60.065578</td>\n",
       "      <td>Dendrocopos minor/XC329937.npy</td>\n",
       "      <td>12.327445</td>\n",
       "      <td>13.547309</td>\n",
       "      <td>drumming</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>Dendrocopos minor</td>\n",
       "      <td>XC329937.mp3</td>\n",
       "      <td>60.065578</td>\n",
       "      <td>Dendrocopos minor/XC329937.npy</td>\n",
       "      <td>42.991427</td>\n",
       "      <td>44.645101</td>\n",
       "      <td>drumming</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0             species    audio_name   duration  \\\n",
       "56           56  Circus aeruginosus  XC269745.mp3  47.777959   \n",
       "57           57  Circus aeruginosus  XC269745.mp3  47.777959   \n",
       "58           58  Circus aeruginosus  XC269745.mp3  47.777959   \n",
       "59           59  Circus aeruginosus  XC269745.mp3  47.777959   \n",
       "60           60  Circus aeruginosus  XC269745.mp3  47.777959   \n",
       "61           61  Circus aeruginosus  XC269745.mp3  47.777959   \n",
       "137         137   Dendrocopos minor  XC329937.mp3  60.065578   \n",
       "138         138   Dendrocopos minor  XC329937.mp3  60.065578   \n",
       "139         139   Dendrocopos minor  XC329937.mp3  60.065578   \n",
       "\n",
       "                        filename_npy      start        end     label  set  \n",
       "56   Circus aeruginosus/XC269745.npy   4.038441   5.702931      call  val  \n",
       "57   Circus aeruginosus/XC269745.npy  17.831900  19.714692      call  val  \n",
       "58   Circus aeruginosus/XC269745.npy  29.005830  29.619776      call  val  \n",
       "59   Circus aeruginosus/XC269745.npy  30.274664  30.943191      call  val  \n",
       "60   Circus aeruginosus/XC269745.npy  34.463183  34.995292      call  val  \n",
       "61   Circus aeruginosus/XC269745.npy  36.605194  38.801770      call  val  \n",
       "137   Dendrocopos minor/XC329937.npy   1.683749   2.903613  drumming  val  \n",
       "138   Dendrocopos minor/XC329937.npy  12.327445  13.547309  drumming  val  \n",
       "139   Dendrocopos minor/XC329937.npy  42.991427  44.645101  drumming  val  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (9, 9)\n",
      "Validation DataFrame shape: (9, 9)\n",
      "Number of rows in dataframe: 9\n",
      "Number of rows in dataframe: 9\n"
     ]
    }
   ],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=1,\n",
    "                      features=features_list,\n",
    "                      avgpool=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(45, 60, 44)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14, 60, 44)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_y = features.val_y\n",
    "display(train_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'Circus aeruginosus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\thato\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\thato\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\thato\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Circus aeruginosus'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit(train_y)\n\u001b[0;32m      2\u001b[0m train_y_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mtransform(train_y)\n\u001b[1;32m----> 3\u001b[0m val_y_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(label_encoder\u001b[38;5;241m.\u001b[39minverse_transform([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoded classes for [0, 1, 2]:\u001b[39m\u001b[38;5;124m\"\u001b[39m, classes)\n",
      "File \u001b[1;32mc:\\Users\\thato\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thato\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'Circus aeruginosus'"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(train_y))\n",
    "display(train_y[:10])\n",
    "\n",
    "display(len(val_y))\n",
    "display(val_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y\n",
    "val_features['label'] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/Annotated/NotAveragePooled/split_features_6s_mel.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram', 'mfcc']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=1,\n",
    "                      features=features_list,\n",
    "                      avgpool=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = features.val_y\n",
    "display(train_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(train_y))\n",
    "display(train_y[:10])\n",
    "\n",
    "display(len(val_y))\n",
    "display(val_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y\n",
    "val_features['label'] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/Annotated/NotAveragePooled/split_features_6s_mel_mfcc.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram', 'mfcc', 'chroma']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc', 'chroma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=1,\n",
    "                      features=features_list,\n",
    "                      avgpool=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = features.val_y\n",
    "display(train_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(train_y))\n",
    "display(train_y[:10])\n",
    "\n",
    "display(len(val_y))\n",
    "display(val_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y\n",
    "val_features['label'] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/NotAnnotated/AveragePooled/split_features_6s_mel_mfcc_chroma.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram', 'mfcc', 'chroma', 'rms']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc', 'chroma', 'rms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=1,\n",
    "                      features=features_list,\n",
    "                      avgpool=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = features.val_y\n",
    "display(train_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(train_y))\n",
    "display(train_y[:10])\n",
    "\n",
    "display(len(val_y))\n",
    "display(val_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y\n",
    "val_features['label'] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/NotAnnotated/AveragePooled/split_features_6s_all.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
