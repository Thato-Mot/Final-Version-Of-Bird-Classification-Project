{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Extraction Methods: Imbalanced Data With Annotations**\n",
    "\n",
    "- *Key Features*: [MFCCs, Mel-Spectrograms, Chroma Frequencies, RMS Power]\n",
    "- *Key Manipulations*: [Varying Window Sizes, Normalization, Average Pooling (Compression), Filtering]\n",
    "- *Process Assistence*: [Converting them to numpy arrays now, easy label access across features]\n",
    "- *Conversion*: [To numpy arrays and pkl files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Libraries for audio\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Training and Testing Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for normalization & avgpooling features\n",
    "import tensorflow as tf\n",
    "# for preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Operational\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import scipy.ndimage\n",
    "import pygame\n",
    "import time\n",
    "from scipy.signal import butter, filtfilt\n",
    "import random\n",
    "import IPython.display as ipd\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabels to be reused\n",
    "path = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/audio_files' \n",
    "npy_path = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/train_audio_npy/' \n",
    "train_csv = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/train-not-annotated.csv' \n",
    "annotated_train_csv = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/trainval-split/trainval-annotated.csv'\n",
    "not_annotated_splt = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/trainval-split/trainval.csv'\n",
    "sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_data = pd.read_csv(annotated_train_csv)\n",
    "train_data = trainval_data[trainval_data['set'] == 'tr']\n",
    "val_data = trainval_data[trainval_data['set'] == 'val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating a class to do the extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extraction:\n",
    "  def __init__(self, train_df, val_df, window_size, overlap=0.5, npy_path=npy_path, sr=sr, n_mels=60, n_mfcc=20, n_chroma=12, features=['mfcc'], normalize=True, avgpool=False):\n",
    "    \"\"\"\n",
    "    Instantiate the Extraction class to extract features.\n",
    "\n",
    "    Parameters:\n",
    "      sr (int): Sample rate of the audio files.\n",
    "      n_mfccs (int): Number of MFCCs to extract.\n",
    "      n_mels (int): Number of Mel bands to extract.\n",
    "      n_chroma (int): Number of chroma bins to use.\n",
    "      features (list): List of features to extract.\n",
    "        accepted features: 'mfcc', 'chroma', 'rms', 'melspectrogram'.\n",
    "      normalize (bool): Whether to normalize the features.\n",
    "      maxpool (bool): Whether to maxpool the features.\n",
    "    \"\"\"\n",
    "    \n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.npy_path = npy_path\n",
    "    self.window_size = window_size\n",
    "    self.overlap = overlap\n",
    "    self.sr = sr\n",
    "    self.n_mels = n_mels\n",
    "    self.n_mfcc = n_mfcc\n",
    "    self.n_chroma = n_chroma\n",
    "\n",
    "     # confirm features have been specified\n",
    "    assert len(features) != 0, \"Must Specify At Least One Feature In The Form Of A List.\"\n",
    "    self.features = features\n",
    "\n",
    "    self.accepted_feature = ['mfcc', 'chroma', 'rms', 'melspectrogram']\n",
    "    for feature in self.features:\n",
    "      assert feature in self.accepted_feature, f\"{feature} is not an accepted feature, only 'mfcc', 'chroma', 'rms', 'melspectrogram' are accepted features.\"\n",
    "\n",
    "    self.normalize = normalize\n",
    "    self.avgpool = avgpool\n",
    "\n",
    "    print(f\"Train DataFrame shape: {train_df.shape}\")\n",
    "    print(f\"Validation DataFrame shape: {val_df.shape}\")\n",
    "\n",
    "    # extract train and val labels and features\n",
    "    self.train_y, self.train_features = self.feature_extraction(self.train_df, window_size=self.window_size)\n",
    "    self.val_y, self.val_features = self.feature_extraction(self.val_df, window_size=self.window_size)\n",
    "\n",
    "    # process the features by average pooling\n",
    "    self.train_features, self.val_features = self.process_features(self.train_features, self.val_features)\n",
    "\n",
    "    \n",
    "  \n",
    "\n",
    "  def normalize_audio(self, audio):\n",
    "    return (audio - np.min(audio)) / (np.max(audio) - np.min(audio))\n",
    "  \n",
    "  def bandpass_filter(self, audio, lowcut=800, highcut=8000, order=4):\n",
    "    nyquist = 0.5 * self.sr  # Nyquist frequency\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    filtered_audio = filtfilt(b, a, audio)\n",
    "    return filtered_audio\n",
    "  \n",
    "  def generate_pink_noise(self, num_samples):\n",
    "    white_noise = np.random.randn(num_samples)\n",
    "    \n",
    "    # Apply a filter to convert white noise into pink noise (1/f noise)\n",
    "    X = np.fft.rfft(white_noise)\n",
    "    S = np.arange(1, len(X) + 1)  # Frequency scaling\n",
    "    pink_noise = np.fft.irfft(X / S)\n",
    "\n",
    "    if len(pink_noise) < num_samples:\n",
    "        # Pad with zeros if the length is less than num_samples\n",
    "        pink_noise = np.pad(pink_noise, (0, num_samples - len(pink_noise)), mode='constant')\n",
    "    elif len(pink_noise) > num_samples:\n",
    "        # Trim if necessary\n",
    "        pink_noise = pink_noise[:num_samples]\n",
    "    \n",
    "    return self.normalize_audio(pink_noise)\n",
    "  \n",
    "  def pad_with_noise(self, audio_data, window_length, window_samples):\n",
    "    current_length = librosa.get_duration(y=audio_data, sr=self.sr)\n",
    "\n",
    "    if current_length > window_length:\n",
    "        return audio_data\n",
    "    \n",
    "    target_length_samples = int(window_length * sr) \n",
    "    current_length_samples = window_samples\n",
    "    padding_length_samples = target_length_samples - current_length_samples\n",
    "\n",
    "    assert target_length_samples == (current_length_samples+padding_length_samples)\n",
    "    \n",
    "    # Generate pink noise to pad with\n",
    "    pink_noise = self.generate_pink_noise(padding_length_samples)\n",
    "    padded_audio = np.concatenate([audio_data, pink_noise])\n",
    "    # if len(padded_audio) < target_length_samples:\n",
    "    #     padded_audio = np.append(padded_audio, self.generate_pink_noise(1))\n",
    "\n",
    "    assert target_length_samples == len(padded_audio)\n",
    "    \n",
    "    return padded_audio\n",
    "  \n",
    "  def avg_pooling_keras(self, feature):\n",
    "    # Clear the previous Keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Define the input shape based on features\n",
    "    input_shape = feature.shape[1:]  # (n_mels, time_steps)\n",
    "\n",
    "    # Create the Keras model for average pooling\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    pooled = tf.keras.layers.GlobalAveragePooling1D()(inputs)\n",
    "    pooling_model = tf.keras.models.Model(inputs=inputs, outputs=pooled)\n",
    "\n",
    "    # Perform pooling using the model\n",
    "    pooled_features = pooling_model.predict(feature)\n",
    "\n",
    "    return pooled_features\n",
    "\n",
    "#-------------------------Feature Extraction---------------------------------------\n",
    "  def extract_mfcc(self, window):\n",
    "    mfcc = librosa.feature.mfcc(y=window, sr=self.sr, n_mfcc=self.n_mfcc)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(mfcc)\n",
    "    else:\n",
    "      return mfcc\n",
    "\n",
    "\n",
    "  def extract_chroma(self, window):\n",
    "    chroma = librosa.feature.chroma_stft(y=window, sr=self.sr, n_chroma=self.n_chroma)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(chroma)\n",
    "    else:\n",
    "      return chroma\n",
    "   \n",
    "\n",
    "  def extract_rms(self, window):\n",
    "    return librosa.feature.rms(y=window)\n",
    "\n",
    "  def extract_melspectrogram(self, window):\n",
    "    mel = librosa.feature.melspectrogram(y=window, sr=self.sr, n_mels=self.n_mels)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(mel)\n",
    "    else:\n",
    "      return mel\n",
    "    \n",
    "  def avgpooling(self, train_X, val_X, n_time, n_features):\n",
    "    \"\"\"\n",
    "    Average pooling the train and val features.\n",
    "\n",
    "    Parameters:\n",
    "      train_X (npy): Training feature array of shape (batch_size, n_features, n_time)\n",
    "      val_X (npy): Validation feature array of shape (batch_size, n_features, n_time)\n",
    "      n_time (int): Time axis\n",
    "      n_features (int): Feature axis\n",
    "\n",
    "    Returns:\n",
    "      train_X (npy): Avgpooled training feature array of shape (batch_size, n_features)\n",
    "      val_X (npy): Avgpooled validation feature array of shape (batch_size, n_features)\n",
    "    \"\"\"\n",
    "    # Clear the Keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Create the Keras input layer with shape (n_features, n_time)\n",
    "    input_layer = tf.keras.layers.Input(shape=(n_features, n_time))\n",
    "    \n",
    "    # Apply average pooling over the time axis (axis=-1) to reduce n_time\n",
    "    avg_pool = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1))(input_layer)\n",
    "    \n",
    "    # Build the model\n",
    "    pooling_model = tf.keras.models.Model(inputs=input_layer, outputs=avg_pool)\n",
    "\n",
    "    # Use the model to apply average pooling on the training and validation features\n",
    "    train_X = pooling_model.predict(train_X)\n",
    "    val_X = pooling_model.predict(val_X)\n",
    "\n",
    "    return train_X, val_X\n",
    "\n",
    "    \n",
    "  def process_features(self, train_features_dict, val_features_dict):\n",
    "    for each in train_features_dict.keys():\n",
    "      \n",
    "      if each == 'mfcc':\n",
    "        n_features=self.n_mfcc\n",
    "      elif each == 'chroma':\n",
    "        n_features=self.n_chroma\n",
    "      elif each == 'rms':\n",
    "        n_features=1\n",
    "      elif each == 'melspectrogram':\n",
    "        n_features=self.n_mels\n",
    "      \n",
    "      train_feature = train_features_dict[each]\n",
    "      val_feature = val_features_dict[each]\n",
    "\n",
    "      if self.avgpool:\n",
    "        train_features_dict[each], val_features_dict[each] = self.avgpooling(train_feature, val_feature, n_time=train_feature.shape[2], n_features=n_features)\n",
    "      else:\n",
    "        train_features_dict[each], val_features_dict[each] = train_features_dict[each], val_features_dict[each]\n",
    "    \n",
    "    return train_features_dict, val_features_dict\n",
    "      \n",
    "\n",
    "  def feature_extraction(self, dataframe, window_size, filter=True):\n",
    "    y = [] # To hold the labels\n",
    "    features_dict = {item: [] for item in self.features} # Create a key for each feature listed\n",
    "    print(f\"Number of rows in dataframe: {len(dataframe)}\")\n",
    "    for _, row in tqdm(dataframe.iterrows(), desc=\"Processing data\", total=len(dataframe)):\n",
    "          label = row['species']\n",
    "          file_path = os.path.join(self.npy_path, row['filename_npy'])\n",
    "          start = row['start']\n",
    "          end = row['end']\n",
    "\n",
    "          # print(f\"Processing file: {file_path}\")\n",
    "\n",
    "          try:\n",
    "            \n",
    "              audio = np.load(file_path)\n",
    "          except FileNotFoundError:\n",
    "              print(f\"File not found: {file_path}\")\n",
    "              continue\n",
    "\n",
    "\n",
    "          start = int(start * sr)\n",
    "          end = int(end * sr)+512\n",
    "\n",
    "\n",
    "\n",
    "          if end > len(audio):\n",
    "             end = len(audio)\n",
    "\n",
    "          sample = audio[start:end]\n",
    "\n",
    "          if len(sample) < 512:\n",
    "                continue\n",
    "\n",
    "          sample = self.normalize_audio(sample)\n",
    "\n",
    "          sample = self.pad_with_noise(sample, window_length=self.window_size, window_samples=len(sample))\n",
    "          # print(len(sample))\n",
    "\n",
    "          if filter:\n",
    "                  sample = self.bandpass_filter(sample)\n",
    "\n",
    "          window_samples = int(window_size * self.sr)\n",
    "          hop_samples = int(window_samples * (1 - self.overlap))  # For overlapping\n",
    "\n",
    "          # Break the audio into windows with the specified overlap\n",
    "          audio_windows = librosa.util.frame(sample, frame_length=window_samples, hop_length=hop_samples).T\n",
    "          \n",
    "          \n",
    "          # display(label)\n",
    "          \n",
    "          for _, window in enumerate(audio_windows):\n",
    "              \n",
    "              y.append(label)\n",
    "\n",
    "              if len(window) < window_samples:\n",
    "                  if len(window) < 512*2:\n",
    "                     continue\n",
    "                  else:\n",
    "                      window = self.pad_with_noise(window, window_length=window_size)\n",
    "              \n",
    "              # Feature Extraction FR --------------------------------------------------------------------\n",
    "              # dynatically call the extract_x function to extract the listed features\n",
    "              for feature in self.features:\n",
    "                extract = f\"extract_{feature}\"\n",
    "                if hasattr(self, extract) and callable(func := getattr(self, extract)):\n",
    "                  features_dict[feature].append(func(window))\n",
    "\n",
    "          # cast lists to np arrays\n",
    "    for each in features_dict.keys():\n",
    "              features_dict[each] = np.array(features_dict[each])\n",
    "\n",
    "    y = np.array(y)\n",
    "\n",
    "          # If not using average pooling, return resized features\n",
    "    return y, features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Average Pooling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Window Size = 1s**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (3444, 9)\n",
      "Validation DataFrame shape: (834, 9)\n",
      "Number of rows in dataframe: 3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 3444/3444 [01:00<00:00, 56.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataframe: 834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 834/834 [00:13<00:00, 60.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\thato\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step\n"
     ]
    }
   ],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=1,\n",
    "                      features=features_list,\n",
    "                      avgpool=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12565,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12565, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3318,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3318, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_y = features.val_y\n",
    "display(val_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes for [0, 1, 2]: ['Acrocephalus arundinaceus', 'Acrocephalus melanopogon', 'Acrocephalus scirpaceus']\n",
      "Encoded training labels: [ 9  9  9 ... 17 17 17]\n",
      "Encoded validation labels: [14 14 14 ...  4  4  4]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12565"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3318"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([14, 14, 14, 14, 14, 14, 10, 10, 10, 10])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(train_y_encoded))\n",
    "display(train_y_encoded[:10])\n",
    "\n",
    "display(len(val_y_encoded))\n",
    "display(val_y_encoded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y_encoded\n",
    "val_features['label'] = val_y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'melspectrogram': array([[9.4866091e-06, 9.5487494e-06, 9.6551566e-06, ..., 9.8847534e-07,\n",
       "          9.3044491e-07, 9.0232516e-07],\n",
       "         [1.2129851e-05, 1.2414495e-05, 1.2921279e-05, ..., 5.2223759e-06,\n",
       "          4.9851474e-06, 4.8430848e-06],\n",
       "         [5.8306232e-05, 5.9333925e-05, 6.1116712e-05, ..., 1.7024886e-06,\n",
       "          1.6033545e-06, 1.5549887e-06],\n",
       "         ...,\n",
       "         [1.2095724e-04, 1.2229703e-04, 1.2461811e-04, ..., 2.1898311e-06,\n",
       "          1.1668556e-06, 1.0314271e-06],\n",
       "         [1.9102510e-05, 1.9464049e-05, 2.0094065e-05, ..., 4.9249811e-06,\n",
       "          4.0005261e-06, 3.6747458e-06],\n",
       "         [4.3214677e-05, 4.4297904e-05, 4.6190373e-05, ..., 1.4690548e-06,\n",
       "          7.8608684e-07, 7.2303249e-07]], dtype=float32),\n",
       "  'label': array([ 9,  9,  9, ..., 17, 17, 17])},\n",
       " 'val': {'melspectrogram': array([[4.8846392e-05, 4.9467966e-05, 5.0583865e-05, ..., 2.4733069e-06,\n",
       "          8.2670647e-07, 7.3230768e-07],\n",
       "         [3.8189260e-06, 3.7921482e-06, 3.7431978e-06, ..., 2.2706577e-06,\n",
       "          6.3330640e-07, 5.7916708e-07],\n",
       "         [2.2262584e-05, 2.2888538e-05, 2.3980747e-05, ..., 1.9094709e-06,\n",
       "          3.8262090e-07, 3.5721015e-07],\n",
       "         ...,\n",
       "         [1.7466613e-05, 1.7916813e-05, 1.8702473e-05, ..., 7.2764919e-06,\n",
       "          6.2982085e-06, 5.9282347e-06],\n",
       "         [1.3407597e-05, 1.3968666e-05, 1.4955254e-05, ..., 2.6093724e-06,\n",
       "          1.8155938e-06, 1.5626828e-06],\n",
       "         [9.7187722e-06, 1.0358767e-05, 1.1470781e-05, ..., 1.0146683e-05,\n",
       "          9.4083061e-06, 9.1177999e-06]], dtype=float32),\n",
       "  'label': array([14, 14, 14, ...,  4,  4,  4])}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/Annotated/AveragePooled/split_features_1s_mel.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram', 'mfcc']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (3444, 9)\n",
      "Validation DataFrame shape: (834, 9)\n",
      "Number of rows in dataframe: 3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 3444/3444 [01:43<00:00, 33.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataframe: 834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 834/834 [00:27<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n"
     ]
    }
   ],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=1,\n",
    "                      features=features_list,\n",
    "                      avgpool=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12565,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12565, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mfcc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12565, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3318,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3318, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mfcc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3318, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_y = features.val_y\n",
    "display(val_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes for [0, 1, 2]: ['Acrocephalus arundinaceus', 'Acrocephalus melanopogon', 'Acrocephalus scirpaceus']\n",
      "Encoded training labels: [ 9  9  9 ... 17 17 17]\n",
      "Encoded validation labels: [14 14 14 ...  4  4  4]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12565"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3318"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([14, 14, 14, 14, 14, 14, 10, 10, 10, 10])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(train_y_encoded))\n",
    "display(train_y_encoded[:10])\n",
    "\n",
    "display(len(val_y_encoded))\n",
    "display(val_y_encoded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y_encoded\n",
    "val_features['label'] = val_y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'melspectrogram': array([[9.4866091e-06, 9.5487494e-06, 9.6551566e-06, ..., 9.8847534e-07,\n",
       "          9.3044491e-07, 9.0232516e-07],\n",
       "         [1.2129851e-05, 1.2414495e-05, 1.2921279e-05, ..., 5.2223759e-06,\n",
       "          4.9851474e-06, 4.8430848e-06],\n",
       "         [5.8306232e-05, 5.9333925e-05, 6.1116712e-05, ..., 1.7024886e-06,\n",
       "          1.6033545e-06, 1.5549887e-06],\n",
       "         ...,\n",
       "         [6.9514776e-06, 6.9201660e-06, 6.8409195e-06, ..., 2.1560011e-06,\n",
       "          1.2065759e-06, 1.0922661e-06],\n",
       "         [1.9102510e-05, 1.9464049e-05, 2.0094065e-05, ..., 4.9249811e-06,\n",
       "          4.0005261e-06, 3.6747458e-06],\n",
       "         [5.4058899e-05, 5.5537719e-05, 5.8154397e-05, ..., 9.8274654e-07,\n",
       "          4.5612131e-07, 4.3058299e-07]], dtype=float32),\n",
       "  'mfcc': array([[-1.        , -0.03889354, -0.64160925, ..., -0.02376524,\n",
       "           0.02349628, -0.00874254],\n",
       "         [-1.        , -0.0368154 , -0.633421  , ..., -0.02121266,\n",
       "           0.0290794 , -0.01421679],\n",
       "         [-1.        , -0.028492  , -0.6135318 , ..., -0.01412221,\n",
       "           0.03116367, -0.02399334],\n",
       "         ...,\n",
       "         [-1.        , -0.16097644, -0.41854694, ..., -0.02413693,\n",
       "          -0.00124187, -0.02697098],\n",
       "         [-1.        , -0.23834963, -0.2839626 , ..., -0.02419488,\n",
       "          -0.01770034, -0.02050554],\n",
       "         [-1.        , -0.17950968, -0.49444035, ..., -0.02029891,\n",
       "          -0.00813901, -0.02340224]], dtype=float32),\n",
       "  'label': array([ 9,  9,  9, ..., 17, 17, 17])},\n",
       " 'val': {'melspectrogram': array([[1.9323090e-04, 1.9501889e-04, 1.9803228e-04, ..., 2.0769555e-06,\n",
       "          6.0800352e-07, 5.7294477e-07],\n",
       "         [7.6455268e-05, 7.7812241e-05, 8.0148813e-05, ..., 2.1114861e-06,\n",
       "          4.3825577e-07, 3.9663411e-07],\n",
       "         [1.9555049e-05, 2.0054757e-05, 2.0946320e-05, ..., 2.4271978e-06,\n",
       "          6.4533180e-07, 5.5217100e-07],\n",
       "         ...,\n",
       "         [1.7466613e-05, 1.7916813e-05, 1.8702473e-05, ..., 7.2764919e-06,\n",
       "          6.2982085e-06, 5.9282347e-06],\n",
       "         [1.3407597e-05, 1.3968666e-05, 1.4955254e-05, ..., 2.6093724e-06,\n",
       "          1.8155938e-06, 1.5626828e-06],\n",
       "         [9.7187722e-06, 1.0358767e-05, 1.1470781e-05, ..., 1.0146683e-05,\n",
       "          9.4083061e-06, 9.1177999e-06]], dtype=float32),\n",
       "  'mfcc': array([[-1.        , -0.07985248, -0.5294543 , ..., -0.01511982,\n",
       "           0.02362318, -0.04137849],\n",
       "         [-1.        , -0.05893915, -0.4736763 , ..., -0.01638399,\n",
       "           0.01888123, -0.03658585],\n",
       "         [-1.        , -0.05814879, -0.4884737 , ..., -0.01721007,\n",
       "           0.02012674, -0.03574475],\n",
       "         ...,\n",
       "         [-1.        , -0.11676493, -0.63356787, ..., -0.02054858,\n",
       "           0.00264495, -0.03115977],\n",
       "         [-1.        , -0.10826456, -0.5855394 , ..., -0.01785684,\n",
       "           0.00353515, -0.03165892],\n",
       "         [-1.        , -0.07664731, -0.5071386 , ..., -0.01156554,\n",
       "           0.00466163, -0.03043199]], dtype=float32),\n",
       "  'label': array([14, 14, 14, ...,  4,  4,  4])}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/Annotated/AveragePooled/split_features_1s_mel_mfcc.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram', 'mfcc', 'chroma']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc', 'chroma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (3444, 9)\n",
      "Validation DataFrame shape: (834, 9)\n",
      "Number of rows in dataframe: 3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  35%|███▍      | 1199/3444 [01:02<01:05, 34.42it/s]c:\\Users\\thato\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Processing data: 100%|██████████| 3444/3444 [02:48<00:00, 20.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataframe: 834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 834/834 [00:42<00:00, 19.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step\n"
     ]
    }
   ],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=1,\n",
    "                      features=features_list,\n",
    "                      avgpool=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12565,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12565, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mfcc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12565, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'chroma'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12565, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3318,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3318, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mfcc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3318, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'chroma'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3318, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_y = features.val_y\n",
    "display(val_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes for [0, 1, 2]: ['Acrocephalus arundinaceus', 'Acrocephalus melanopogon', 'Acrocephalus scirpaceus']\n",
      "Encoded training labels: [ 9  9  9 ... 17 17 17]\n",
      "Encoded validation labels: [14 14 14 ...  4  4  4]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12565"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3318"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([14, 14, 14, 14, 14, 14, 10, 10, 10, 10])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(train_y_encoded))\n",
    "display(train_y_encoded[:10])\n",
    "\n",
    "display(len(val_y_encoded))\n",
    "display(val_y_encoded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y_encoded\n",
    "val_features['label'] = val_y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'melspectrogram': array([[9.4866091e-06, 9.5487494e-06, 9.6551566e-06, ..., 9.8847534e-07,\n",
       "          9.3044491e-07, 9.0232516e-07],\n",
       "         [1.2129851e-05, 1.2414495e-05, 1.2921279e-05, ..., 5.2223759e-06,\n",
       "          4.9851474e-06, 4.8430848e-06],\n",
       "         [5.8306232e-05, 5.9333925e-05, 6.1116712e-05, ..., 1.7024886e-06,\n",
       "          1.6033545e-06, 1.5549887e-06],\n",
       "         ...,\n",
       "         [8.7809662e-05, 8.9015433e-05, 9.1153270e-05, ..., 1.1500978e-06,\n",
       "          4.3757257e-07, 4.0334126e-07],\n",
       "         [1.9102510e-05, 1.9464049e-05, 2.0094065e-05, ..., 4.9249811e-06,\n",
       "          4.0005261e-06, 3.6747458e-06],\n",
       "         [3.4193312e-05, 3.5084158e-05, 3.6650839e-05, ..., 1.0402787e-06,\n",
       "          5.3121545e-07, 5.1639358e-07]], dtype=float32),\n",
       "  'mfcc': array([[-1.        , -0.03889354, -0.64160925, ..., -0.02376524,\n",
       "           0.02349628, -0.00874254],\n",
       "         [-1.        , -0.0368154 , -0.633421  , ..., -0.02121266,\n",
       "           0.0290794 , -0.01421679],\n",
       "         [-1.        , -0.028492  , -0.6135318 , ..., -0.01412221,\n",
       "           0.03116367, -0.02399334],\n",
       "         ...,\n",
       "         [-1.        , -0.15970185, -0.443663  , ..., -0.02533606,\n",
       "           0.00209685, -0.02574544],\n",
       "         [-1.        , -0.23834963, -0.2839626 , ..., -0.02419488,\n",
       "          -0.01770034, -0.02050554],\n",
       "         [-1.        , -0.18328   , -0.49470088, ..., -0.02033736,\n",
       "          -0.00807526, -0.02337172]], dtype=float32),\n",
       "  'chroma': array([[0.28168038, 0.44423884, 0.7954796 , ..., 0.34062782, 0.26789963,\n",
       "          0.24262533],\n",
       "         [0.29354393, 0.39524266, 0.80161744, ..., 0.5290854 , 0.27707702,\n",
       "          0.24435301],\n",
       "         [0.26423457, 0.32508212, 0.5428115 , ..., 0.8181757 , 0.43553543,\n",
       "          0.27263308],\n",
       "         ...,\n",
       "         [0.37614715, 0.38578555, 0.45834696, ..., 0.5139236 , 0.38074872,\n",
       "          0.33736387],\n",
       "         [0.09597728, 0.13536958, 0.2523176 , ..., 0.3600199 , 0.26013952,\n",
       "          0.16794482],\n",
       "         [0.40394926, 0.40183914, 0.43196088, ..., 0.46639946, 0.3875946 ,\n",
       "          0.3913845 ]], dtype=float32),\n",
       "  'label': array([ 9,  9,  9, ..., 17, 17, 17])},\n",
       " 'val': {'melspectrogram': array([[4.9271792e-05, 4.9810216e-05, 5.0750150e-05, ..., 1.7590075e-06,\n",
       "          1.9968201e-07, 1.5576883e-07],\n",
       "         [2.3996256e-05, 2.4281891e-05, 2.4751715e-05, ..., 1.9183371e-06,\n",
       "          4.0804255e-07, 3.7679874e-07],\n",
       "         [3.3185832e-05, 3.3953223e-05, 3.5335772e-05, ..., 3.0677752e-06,\n",
       "          1.2189607e-06, 1.0544190e-06],\n",
       "         ...,\n",
       "         [1.7466613e-05, 1.7916813e-05, 1.8702473e-05, ..., 7.2764919e-06,\n",
       "          6.2982085e-06, 5.9282347e-06],\n",
       "         [1.3407597e-05, 1.3968666e-05, 1.4955254e-05, ..., 2.6093724e-06,\n",
       "          1.8155938e-06, 1.5626828e-06],\n",
       "         [9.7187722e-06, 1.0358767e-05, 1.1470781e-05, ..., 1.0146683e-05,\n",
       "          9.4083061e-06, 9.1177999e-06]], dtype=float32),\n",
       "  'mfcc': array([[-1.        , -0.08283383, -0.5131269 , ..., -0.01740273,\n",
       "           0.02400634, -0.0396682 ],\n",
       "         [-1.        , -0.05347031, -0.44762734, ..., -0.01509358,\n",
       "           0.02094383, -0.0314503 ],\n",
       "         [-1.        , -0.05673461, -0.48673838, ..., -0.0166992 ,\n",
       "           0.02166047, -0.0308893 ],\n",
       "         ...,\n",
       "         [-1.        , -0.11676493, -0.63356787, ..., -0.02054858,\n",
       "           0.00264495, -0.03115977],\n",
       "         [-1.        , -0.10826456, -0.5855394 , ..., -0.01785684,\n",
       "           0.00353515, -0.03165892],\n",
       "         [-1.        , -0.07664731, -0.5071386 , ..., -0.01156554,\n",
       "           0.00466163, -0.03043199]], dtype=float32),\n",
       "  'chroma': array([[0.65636533, 0.5482294 , 0.54489356, ..., 0.67625976, 0.7036252 ,\n",
       "          0.73434067],\n",
       "         [0.58345366, 0.62249875, 0.6350968 , ..., 0.7508402 , 0.72323346,\n",
       "          0.6901304 ],\n",
       "         [0.60404754, 0.5982534 , 0.5814903 , ..., 0.62033314, 0.71315557,\n",
       "          0.6761253 ],\n",
       "         ...,\n",
       "         [0.6464903 , 0.5206767 , 0.43624964, ..., 0.25282976, 0.32724506,\n",
       "          0.6165209 ],\n",
       "         [0.74455017, 0.5956325 , 0.46578252, ..., 0.2800944 , 0.46128023,\n",
       "          0.7216884 ],\n",
       "         [0.61577326, 0.53360295, 0.56813645, ..., 0.41918138, 0.6988415 ,\n",
       "          0.7249389 ]], dtype=float32),\n",
       "  'label': array([14, 14, 14, ...,  4,  4,  4])}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/Annotated/AveragePooled/split_features_1s_mel_mfcc_chroma.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram', 'mfcc', 'chroma', 'rms']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc', 'chroma', 'rms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (3444, 9)\n",
      "Validation DataFrame shape: (834, 9)\n",
      "Number of rows in dataframe: 3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  35%|███▍      | 1201/3444 [01:06<01:04, 34.95it/s]c:\\Users\\thato\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Processing data: 100%|██████████| 3444/3444 [03:04<00:00, 18.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataframe: 834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 834/834 [00:48<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step\n"
     ]
    }
   ],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=1,\n",
    "                      features=features_list,\n",
    "                      avgpool=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12565,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12565, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mfcc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12565, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'chroma'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12565, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rms'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12565, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3318,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'melspectrogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3318, 60)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mfcc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3318, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'chroma'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3318, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rms'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3318, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_y = features.val_y\n",
    "display(val_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes for [0, 1, 2]: ['Acrocephalus arundinaceus', 'Acrocephalus melanopogon', 'Acrocephalus scirpaceus']\n",
      "Encoded training labels: [ 9  9  9 ... 17 17 17]\n",
      "Encoded validation labels: [14 14 14 ...  4  4  4]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12565"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3318"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([14, 14, 14, 14, 14, 14, 10, 10, 10, 10])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(train_y_encoded))\n",
    "display(train_y_encoded[:10])\n",
    "\n",
    "display(len(val_y_encoded))\n",
    "display(val_y_encoded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y_encoded\n",
    "val_features['label'] = val_y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'melspectrogram': array([[9.4866091e-06, 9.5487494e-06, 9.6551566e-06, ..., 9.8847534e-07,\n",
       "          9.3044491e-07, 9.0232516e-07],\n",
       "         [1.2129851e-05, 1.2414495e-05, 1.2921279e-05, ..., 5.2223759e-06,\n",
       "          4.9851474e-06, 4.8430848e-06],\n",
       "         [5.8306232e-05, 5.9333925e-05, 6.1116712e-05, ..., 1.7024886e-06,\n",
       "          1.6033545e-06, 1.5549887e-06],\n",
       "         ...,\n",
       "         [1.7914819e-04, 1.8226101e-04, 1.8773414e-04, ..., 2.3687387e-06,\n",
       "          1.6498615e-06, 1.5470791e-06],\n",
       "         [1.9102510e-05, 1.9464049e-05, 2.0094065e-05, ..., 4.9249811e-06,\n",
       "          4.0005261e-06, 3.6747458e-06],\n",
       "         [9.0032081e-06, 9.2558430e-06, 9.7203119e-06, ..., 9.5587347e-07,\n",
       "          4.5187107e-07, 4.2664561e-07]], dtype=float32),\n",
       "  'mfcc': array([[-1.        , -0.03889354, -0.64160925, ..., -0.02376524,\n",
       "           0.02349628, -0.00874254],\n",
       "         [-1.        , -0.0368154 , -0.633421  , ..., -0.02121266,\n",
       "           0.0290794 , -0.01421679],\n",
       "         [-1.        , -0.028492  , -0.6135318 , ..., -0.01412221,\n",
       "           0.03116367, -0.02399334],\n",
       "         ...,\n",
       "         [-1.        , -0.1546297 , -0.42896062, ..., -0.02429112,\n",
       "           0.00185133, -0.023763  ],\n",
       "         [-1.        , -0.23834963, -0.2839626 , ..., -0.02419488,\n",
       "          -0.01770034, -0.02050554],\n",
       "         [-1.        , -0.18269444, -0.4728804 , ..., -0.02088645,\n",
       "          -0.00905993, -0.02424012]], dtype=float32),\n",
       "  'chroma': array([[0.28168038, 0.44423884, 0.7954796 , ..., 0.34062782, 0.26789963,\n",
       "          0.24262533],\n",
       "         [0.29354393, 0.39524266, 0.80161744, ..., 0.5290854 , 0.27707702,\n",
       "          0.24435301],\n",
       "         [0.26423457, 0.32508212, 0.5428115 , ..., 0.8181757 , 0.43553543,\n",
       "          0.27263308],\n",
       "         ...,\n",
       "         [0.3961731 , 0.4062669 , 0.466302  , ..., 0.5467325 , 0.46560505,\n",
       "          0.3846309 ],\n",
       "         [0.09597728, 0.13536958, 0.2523176 , ..., 0.3600199 , 0.26013952,\n",
       "          0.16794482],\n",
       "         [0.40654755, 0.41130054, 0.41587985, ..., 0.4494035 , 0.38985494,\n",
       "          0.39067504]], dtype=float32),\n",
       "  'rms': array([[0.02573253],\n",
       "         [0.02451546],\n",
       "         [0.02242243],\n",
       "         ...,\n",
       "         [0.05309197],\n",
       "         [0.08728904],\n",
       "         [0.07306994]], dtype=float32),\n",
       "  'label': array([ 9,  9,  9, ..., 17, 17, 17])},\n",
       " 'val': {'melspectrogram': array([[5.1989915e-05, 5.2538897e-05, 5.3492116e-05, ..., 1.8636129e-06,\n",
       "          2.0608599e-07, 1.6636960e-07],\n",
       "         [1.4291744e-04, 1.4515762e-04, 1.4902874e-04, ..., 5.0847398e-06,\n",
       "          3.1790953e-06, 2.8643176e-06],\n",
       "         [2.6025709e-05, 2.6837281e-05, 2.8287852e-05, ..., 3.4162294e-06,\n",
       "          1.4661563e-06, 1.2564024e-06],\n",
       "         ...,\n",
       "         [1.7466613e-05, 1.7916813e-05, 1.8702473e-05, ..., 7.2764919e-06,\n",
       "          6.2982085e-06, 5.9282347e-06],\n",
       "         [1.3407597e-05, 1.3968666e-05, 1.4955254e-05, ..., 2.6093724e-06,\n",
       "          1.8155938e-06, 1.5626828e-06],\n",
       "         [9.7187722e-06, 1.0358767e-05, 1.1470781e-05, ..., 1.0146683e-05,\n",
       "          9.4083061e-06, 9.1177999e-06]], dtype=float32),\n",
       "  'mfcc': array([[-1.        , -0.07569719, -0.4688185 , ..., -0.01384517,\n",
       "           0.02275038, -0.04104686],\n",
       "         [-1.        , -0.0516515 , -0.4366102 , ..., -0.01653684,\n",
       "           0.01892455, -0.03095724],\n",
       "         [-1.        , -0.0584469 , -0.47350252, ..., -0.01544693,\n",
       "           0.02300377, -0.03344856],\n",
       "         ...,\n",
       "         [-1.        , -0.11676493, -0.63356787, ..., -0.02054858,\n",
       "           0.00264495, -0.03115977],\n",
       "         [-1.        , -0.10826456, -0.5855394 , ..., -0.01785684,\n",
       "           0.00353515, -0.03165892],\n",
       "         [-1.        , -0.07664731, -0.5071386 , ..., -0.01156554,\n",
       "           0.00466163, -0.03043199]], dtype=float32),\n",
       "  'chroma': array([[0.51784205, 0.5492613 , 0.6029367 , ..., 0.7912121 , 0.72578454,\n",
       "          0.5943713 ],\n",
       "         [0.6110289 , 0.58575505, 0.5675497 , ..., 0.70730555, 0.7340407 ,\n",
       "          0.6731152 ],\n",
       "         [0.6290362 , 0.62780225, 0.6175032 , ..., 0.73912656, 0.72839034,\n",
       "          0.63569695],\n",
       "         ...,\n",
       "         [0.6464903 , 0.5206767 , 0.43624964, ..., 0.25282976, 0.32724506,\n",
       "          0.6165209 ],\n",
       "         [0.74455017, 0.5956325 , 0.46578252, ..., 0.2800944 , 0.46128023,\n",
       "          0.7216884 ],\n",
       "         [0.61577326, 0.53360295, 0.56813645, ..., 0.41918138, 0.6988415 ,\n",
       "          0.7249389 ]], dtype=float32),\n",
       "  'rms': array([[0.02685305],\n",
       "         [0.01838242],\n",
       "         [0.01808   ],\n",
       "         ...,\n",
       "         [0.03283624],\n",
       "         [0.02899636],\n",
       "         [0.0181786 ]], dtype=float32),\n",
       "  'label': array([14, 14, 14, ...,  4,  4,  4])}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/Annotated/AveragePooled/split_features_1s_all.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
