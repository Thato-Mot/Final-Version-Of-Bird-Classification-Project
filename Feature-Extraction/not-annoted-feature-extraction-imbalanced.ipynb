{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Extraction Methods: Imbalanced Data Without Annotations**\n",
    "\n",
    "- *Key Features*: [MFCCs, Mel-Spectrograms, Chroma Frequencies, RMS Power]\n",
    "- *Key Manipulations*: [Varying Window Sizes, Normalization, Average Pooling (Compression), Filtering]\n",
    "- *Process Assistence*: [Converting them to numpy arrays now, easy label access across features]\n",
    "- *Conversion*: [To numpy arrays and pkl files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Libraries for audio\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Training and Testing Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for normalization & avgpooling features\n",
    "import tensorflow as tf\n",
    "# for preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Operational\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import scipy.ndimage\n",
    "import pygame\n",
    "import time\n",
    "from scipy.signal import butter, filtfilt\n",
    "import random\n",
    "import IPython.display as ipd\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabels to be reused\n",
    "path = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/audio_files' \n",
    "npy_path = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/train_audio_npy/' \n",
    "train_csv = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/train-not-annotated.csv' \n",
    "annotated_train_csv = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/train-annotated.csv'\n",
    "not_annotated_splt = 'C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/trainval-split/trainval.csv'\n",
    "sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_data = pd.read_csv(not_annotated_splt)\n",
    "train_data = trainval_data[trainval_data['set'] == 'tr']\n",
    "val_data = trainval_data[trainval_data['set'] == 'val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating a class to do the extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extraction:\n",
    "  def __init__(self, train_df, val_df, window_size, overlap=0.5, npy_path=npy_path, sr=sr, n_mels=60, n_mfcc=20, n_chroma=12, features=['mfcc'], normalize=True, avgpool=False):\n",
    "    \"\"\"\n",
    "    Instantiate the Extraction class to extract features.\n",
    "\n",
    "    Parameters:\n",
    "      sr (int): Sample rate of the audio files.\n",
    "      n_mfccs (int): Number of MFCCs to extract.\n",
    "      n_mels (int): Number of Mel bands to extract.\n",
    "      n_chroma (int): Number of chroma bins to use.\n",
    "      features (list): List of features to extract.\n",
    "        accepted features: 'mfcc', 'chroma', 'rms', 'melspectrogram'.\n",
    "      normalize (bool): Whether to normalize the features.\n",
    "      maxpool (bool): Whether to maxpool the features.\n",
    "    \"\"\"\n",
    "    \n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.npy_path = npy_path\n",
    "    self.window_size = window_size\n",
    "    self.overlap = overlap\n",
    "    self.sr = sr\n",
    "    self.n_mels = n_mels\n",
    "    self.n_mfcc = n_mfcc\n",
    "    self.n_chroma = n_chroma\n",
    "\n",
    "     # confirm features have been specified\n",
    "    assert len(features) != 0, \"Must Specify At Least One Feature In The Form Of A List.\"\n",
    "    self.features = features\n",
    "\n",
    "    self.accepted_feature = ['mfcc', 'chroma', 'rms', 'melspectrogram']\n",
    "    for feature in self.features:\n",
    "      assert feature in self.accepted_feature, f\"{feature} is not an accepted feature, only 'mfcc', 'chroma', 'rms', 'melspectrogram' are accepted features.\"\n",
    "\n",
    "    self.normalize = normalize\n",
    "    self.avgpool = avgpool\n",
    "\n",
    "    # extract train and val labels and features\n",
    "    self.train_y, self.train_features = self.feature_extraction(train_df)\n",
    "    self.val_y, self.val_features = self.feature_extraction(val_df)\n",
    "\n",
    "    # process the features by average pooling\n",
    "    self.train_features, self.val_features = self.process_features(self.train_features, self.val_features)\n",
    "\n",
    "    \n",
    "  \n",
    "\n",
    "  def normalize_audio(self, audio):\n",
    "    return (audio - np.min(audio)) / (np.max(audio) - np.min(audio))\n",
    "  \n",
    "  def bandpass_filter(self, audio, lowcut=800, highcut=8000, order=4):\n",
    "    nyquist = 0.5 * self.sr  # Nyquist frequency\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    filtered_audio = filtfilt(b, a, audio)\n",
    "    return filtered_audio\n",
    "  \n",
    "  def generate_pink_noise(self, num_samples):\n",
    "    white_noise = np.random.randn(num_samples)\n",
    "    \n",
    "    # Apply a filter to convert white noise into pink noise (1/f noise)\n",
    "    X = np.fft.rfft(white_noise)\n",
    "    S = np.arange(1, len(X) + 1)  # Frequency scaling\n",
    "    pink_noise = np.fft.irfft(X / S)\n",
    "    \n",
    "    return self.normalize_audio(pink_noise)\n",
    "  \n",
    "  def pad_with_noise(self, audio_data, window_length):\n",
    "    current_length = librosa.get_duration(y=audio_data, sr=self.sr)\n",
    "    if current_length >= window_length:\n",
    "        return audio_data\n",
    "    \n",
    "    target_length_samples = int(window_length * sr) + 1\n",
    "    current_length_samples = len(audio_data)\n",
    "    padding_length_samples = target_length_samples - current_length_samples\n",
    "    \n",
    "    # Generate pink noise to pad with\n",
    "    pink_noise = self.generate_pink_noise(padding_length_samples)\n",
    "    padded_audio = np.concatenate([audio_data, pink_noise])\n",
    "    \n",
    "    return padded_audio\n",
    "  \n",
    "  def avg_pooling_keras(self, feature):\n",
    "    # Clear the previous Keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Define the input shape based on features\n",
    "    input_shape = feature.shape[1:]  # (n_mels, time_steps)\n",
    "\n",
    "    # Create the Keras model for average pooling\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    pooled = tf.keras.layers.GlobalAveragePooling1D()(inputs)\n",
    "    pooling_model = tf.keras.models.Model(inputs=inputs, outputs=pooled)\n",
    "\n",
    "    # Perform pooling using the model\n",
    "    pooled_features = pooling_model.predict(feature)\n",
    "\n",
    "    return pooled_features\n",
    "\n",
    "#-------------------------Feature Extraction---------------------------------------\n",
    "  def extract_mfcc(self, window):\n",
    "    mfcc = librosa.feature.mfcc(y=window, sr=self.sr, n_mfcc=self.n_mfcc)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(mfcc)\n",
    "    else:\n",
    "      return mfcc\n",
    "\n",
    "\n",
    "  def extract_chroma(self, window):\n",
    "    chroma = librosa.feature.chroma_stft(y=window, sr=self.sr, n_chroma=self.n_chroma)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(chroma)\n",
    "    else:\n",
    "      return chroma\n",
    "   \n",
    "\n",
    "  def extract_rms(self, window):\n",
    "    return librosa.feature.rms(y=window)\n",
    "\n",
    "  def extract_melspectrogram(self, window):\n",
    "    mel = librosa.feature.melspectrogram(y=window, sr=self.sr, n_mels=self.n_mels)\n",
    "    if self.normalize:\n",
    "      return librosa.util.normalize(mel)\n",
    "    else:\n",
    "      return mel\n",
    "    \n",
    "  def avgpooling(self, train_X, val_X, n_time, n_features):\n",
    "    \"\"\"\n",
    "    Average pooling the train and val features.\n",
    "\n",
    "    Parameters:\n",
    "      train_X (npy): Training feature array of shape (batch_size, n_features, n_time)\n",
    "      val_X (npy): Validation feature array of shape (batch_size, n_features, n_time)\n",
    "      n_time (int): Time axis\n",
    "      n_features (int): Feature axis\n",
    "\n",
    "    Returns:\n",
    "      train_X (npy): Avgpooled training feature array of shape (batch_size, n_features)\n",
    "      val_X (npy): Avgpooled validation feature array of shape (batch_size, n_features)\n",
    "    \"\"\"\n",
    "    # Clear the Keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Create the Keras input layer with shape (n_features, n_time)\n",
    "    input_layer = tf.keras.layers.Input(shape=(n_features, n_time))\n",
    "    \n",
    "    # Apply average pooling over the time axis (axis=-1) to reduce n_time\n",
    "    avg_pool = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1))(input_layer)\n",
    "    \n",
    "    # Build the model\n",
    "    pooling_model = tf.keras.models.Model(inputs=input_layer, outputs=avg_pool)\n",
    "\n",
    "    # Use the model to apply average pooling on the training and validation features\n",
    "    train_X = pooling_model.predict(train_X)\n",
    "    val_X = pooling_model.predict(val_X)\n",
    "\n",
    "    return train_X, val_X\n",
    "\n",
    "    \n",
    "  def process_features(self, train_features_dict, val_features_dict):\n",
    "    for each in train_features_dict.keys():\n",
    "      \n",
    "      if each == 'mfcc':\n",
    "        n_features=self.n_mfcc\n",
    "      elif each == 'chroma':\n",
    "        n_features=self.n_chroma\n",
    "      elif each == 'rms':\n",
    "        n_features=1\n",
    "      elif each == 'melspectrogram':\n",
    "        n_features=self.n_mels\n",
    "      \n",
    "      train_feature = train_features_dict[each]\n",
    "      val_feature = val_features_dict[each]\n",
    "\n",
    "      if self.avgpool:\n",
    "        train_features_dict[each], val_features_dict[each] = self.avgpooling(train_feature, val_feature, n_time=train_feature.shape[2], n_features=n_features)\n",
    "      else:\n",
    "        train_features_dict[each], val_features_dict[each] = train_features_dict[each], val_features_dict[each]\n",
    "    \n",
    "    return train_features_dict, val_features_dict\n",
    "      \n",
    "\n",
    "  def feature_extraction(self, dataframe, window_size=6, filter=True):\n",
    "    y = [] # To hold the labels\n",
    "    features_dict = {item: [] for item in self.features} # Create a key for each feature listed\n",
    "\n",
    "    for _, row in dataframe.iterrows():\n",
    "          label = row['species']\n",
    "          file_path = self.npy_path + row['filename_npy']\n",
    "\n",
    "          \n",
    "          audio = np.load(file_path)\n",
    "          audio = self.normalize_audio(audio)\n",
    "          audio = self.pad_with_noise(audio, window_length=window_size)\n",
    "          if filter:\n",
    "                  audio = self.bandpass_filter(audio)\n",
    "\n",
    "          window_samples = int(window_size * self.sr)\n",
    "          hop_samples = int(window_samples * (1 - self.overlap))  # For overlapping\n",
    "\n",
    "          # Break the audio into windows with the specified overlap\n",
    "          audio_windows = librosa.util.frame(audio, frame_length=window_samples, hop_length=hop_samples).T\n",
    "\n",
    "          for _, window in enumerate(audio_windows):\n",
    "              \n",
    "              y.append(label)\n",
    "\n",
    "              if len(window) < window_samples:\n",
    "                  window = self.pad_with_noise(window, window_length=window_size)\n",
    "              \n",
    "              # Feature Extraction FR --------------------------------------------------------------------\n",
    "              # dynatically call the extract_x function to extract the listed features\n",
    "              for feature in self.features:\n",
    "                extract = f\"extract_{feature}\"\n",
    "                if hasattr(self, extract) and callable(func := getattr(self, extract)):\n",
    "                  features_dict[feature].append(func(window))\n",
    "\n",
    "          # cast lists to np arrays\n",
    "          for each in features_dict.keys():\n",
    "            features_dict[each] = np.array(features_dict[each])\n",
    "\n",
    "          y = np.array(y)\n",
    "\n",
    "          # If not using average pooling, return resized features\n",
    "          return y, features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No Average Pooling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Window Size = 6s**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=6,\n",
    "                      features=features_list,\n",
    "                      avgpool=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = features.val_y\n",
    "display(train_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(train_y))\n",
    "display(train_y[:10])\n",
    "\n",
    "display(len(val_y))\n",
    "display(val_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y\n",
    "val_features['label'] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/NotAnnotated/NotAveragePooled/split_features_6s_mel.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram', 'mfcc']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=6,\n",
    "                      features=features_list,\n",
    "                      avgpool=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = features.val_y\n",
    "display(train_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(train_y))\n",
    "display(train_y[:10])\n",
    "\n",
    "display(len(val_y))\n",
    "display(val_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y\n",
    "val_features['label'] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/NotAnnotated/NotAveragePooled/split_features_6s_mel_mfcc.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram', 'mfcc', 'chroma']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc', 'chroma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=6,\n",
    "                      features=features_list,\n",
    "                      avgpool=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = features.val_y\n",
    "display(train_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(train_y))\n",
    "display(train_y[:10])\n",
    "\n",
    "display(len(val_y))\n",
    "display(val_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y\n",
    "val_features['label'] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/NotAnnotated/NotAveragePooled/split_features_6s_mel_mfcc_chroma.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **['melspectrogram', 'mfcc', 'chroma', 'rms']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['melspectrogram', 'mfcc', 'chroma', 'rms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Extraction(train_data,\n",
    "                      val_data,\n",
    "                      window_size=6,\n",
    "                      features=features_list,\n",
    "                      avgpool=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = features.train_y\n",
    "display(train_y.shape)\n",
    "\n",
    "train_features = features.train_features\n",
    "for key in train_features.keys():\n",
    "  display(key)\n",
    "  display(train_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = features.val_y\n",
    "display(train_y.shape)\n",
    "\n",
    "val_features = features.val_features\n",
    "for key in val_features.keys():\n",
    "  display(key)\n",
    "  display(val_features[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(train_y)\n",
    "train_y_encoded = label_encoder.transform(train_y)\n",
    "val_y_encoded = label_encoder.transform(val_y)\n",
    "\n",
    "classes = list(label_encoder.inverse_transform([0, 1, 2]))\n",
    "print(\"Encoded classes for [0, 1, 2]:\", classes)\n",
    "print(\"Encoded training labels:\", train_y_encoded)\n",
    "print(\"Encoded validation labels:\", val_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(train_y))\n",
    "display(train_y[:10])\n",
    "\n",
    "display(len(val_y))\n",
    "display(val_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['label'] = train_y\n",
    "val_features['label'] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = {'train': train_features, 'val': val_features}\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged dictionary to a pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/thato/Documents/Final-Year-Project/Dataset/Project-V4/feature-extraction/NotAnnotated/NotAveragePooled/split_features_6s_all.pkl', 'wb') as file:\n",
    "  pickle.dump(merged_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
